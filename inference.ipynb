{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e0476d9-1143-4027-a0e4-f6c9ae220e45",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821fdf74-f638-4488-9d45-dd01a4eb6f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install\n",
    "import numpy as np\n",
    "import torch\n",
    "import signal\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from transformers import HfArgumentParser, TensorFlowBenchmark, TensorFlowBenchmarkArguments\n",
    "import pandas as pd\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "from transformers import TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Trainer\n",
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53602fda-cc81-45d2-a55e-f7b3e501469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_dataset_dir = '/projects/RTM/aligned_sentences/'\n",
    "# output_dir = '/Users/dw16/Downloads/tmp/byt5_inline_cite_ref_small_words/' # this is just the words\n",
    "output_dir = '/home/dw16/models/byt5_inline_cite_ref_ocr/' # this is just the words\n",
    "output_dir_ = '/home/dw16/models/inferences/' # this is just the words\n",
    "# ender = '_yelpfeast' # yelpfeast/byt5-base-english-ocr-correction\n",
    "# ender = '_small_words' # 100k for training, 5k val\n",
    "ender = 'multilex' # 'ufal/byt5-small-multilexnorm2021-es''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ba2d823-c821-427d-9415-105ed61f060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_timeout = 2.0 # timeout in minutes\n",
    "wait_timeout *= 60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4f7ca68-7de3-4e34-9edf-a9e8e3fe915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_latex = 'test_masked_n10000_20230503.csv'\n",
    "test_df = pd.read_csv(aligned_dataset_dir + test_latex)\n",
    "inds = 0\n",
    "# text = test_df.iloc[inds][\"sentences source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b77822bb-0351-4845-8d87-635fb5f1d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inds = np.arange(0,1) \n",
    "# inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dd1345b-8dc8-40a9-be0e-d14c6d981911",
   "metadata": {},
   "outputs": [],
   "source": [
    "class timeout:\n",
    "    def __init__(self, seconds=1, error_message='Timeout'):\n",
    "        self.seconds = seconds\n",
    "        self.error_message = error_message\n",
    "    def handle_timeout(self, signum, frame):\n",
    "        raise TimeoutError(self.error_message)\n",
    "    def __enter__(self):\n",
    "        signal.signal(signal.SIGALRM, self.handle_timeout)\n",
    "        signal.alarm(self.seconds)\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        signal.alarm(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "822c272f-ed7e-4518-8052-8b22933e374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # byt5-small\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#     \"google/byt5-small\",\n",
    "#     cache_dir=output_dir, \n",
    "# #    max_length=4096\n",
    "#     max_new_tokens=4096\n",
    "# )\n",
    "\n",
    "# # yelpfeast/byt5-base-english-ocr-correction\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#     \"yelpfeast/byt5-base-english-ocr-correction\",\n",
    "#     cache_dir=output_dir, \n",
    "# #    max_length=4096\n",
    "#     max_new_tokens=4096\n",
    "# )\n",
    "\n",
    "#'ufal/byt5-small-multilexnorm2021-es'\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"ufal/byt5-small-multilexnorm2021-es\",\n",
    "    cache_dir=output_dir, \n",
    "#    max_length=4096\n",
    "    max_new_tokens=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "282d959f-2279-4ed6-be14-57d8d92bdc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# snapshot = 'checkpoint-66000'  #for byt5-samll\n",
    "snapshot = 'checkpoint-38000' #ocr\n",
    "# snapshot = None\n",
    "\n",
    "if snapshot == None:\n",
    "    snapshots = glob(output_dir+'checkpoint*')\n",
    "    order = []\n",
    "    for s in snapshots:\n",
    "        order.append(s.split('-')[-1])\n",
    "    argsort = np.argsort(np.array(order).astype('int'))\n",
    "    snapshot = np.array(snapshots)[argsort][-1]\n",
    "else:\n",
    "    snapshot = output_dir + snapshot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e555760-d972-42d3-83bf-a16a0ab99a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(snapshot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8f69a3c-bb5d-45c7-97c8-541aac072eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_specials = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e5bfc5-5c28-4e4f-bac7-2bba067f559f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## google/byt5-small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe15f97-4851-43f8-a798-afcc24708ff9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1 Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "526231dd-02e5-4425-866e-f0aa799764ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inds = 1\n",
    "# text = test_df.iloc[inds][\"sentences source\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a87d171d-42b6-464f-a9b0-5cac07d99c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with timeout(seconds=int(wait_timeout)):\n",
    "#     inputs = tokenizer(text, padding=\"longest\", return_tensors=\"pt\")\n",
    "#     output = model.generate(**inputs)\n",
    "#     output_text = tokenizer.decode(output[0], \n",
    "#                                     skip_special_tokens=skip_specials, \n",
    "#                                     clean_up_tokenization_spaces=True)\n",
    "#     output_text = str(output_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "14cac20d-aadb-4bd2-b656-3217a07c7aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8700a4a1-1345-4094-a2d7-49968cefc0f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8f49acd8-5d91-4062-9f42-71d42624bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inds = np.arange(0,2)\n",
    "# text = test_df.iloc[inds][\"sentences source\"]\n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a167df5d-1878-4ab2-ba15-b71f7bba2ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = test_df.iloc[inds].copy()\n",
    "# df2['predicted_text'] = pd.Series([])\n",
    "\n",
    "# for i in range(text.shape[0]):\n",
    "#     with timeout(seconds=int(wait_timeout)):\n",
    "#         inputs = tokenizer(text[i], padding=\"longest\", return_tensors=\"pt\")\n",
    "#         output = model.generate(**inputs)\n",
    "#         output_text = tokenizer.decode(output[0], \n",
    "#                                         skip_special_tokens=skip_specials, \n",
    "#                                         clean_up_tokenization_spaces=True)\n",
    "#         output_text = str(output_text)\n",
    "# #     df2 = test_df.iloc[inds].copy()\n",
    "#         df2['predicted_text'][i] = output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f35fa273-4ce5-404d-895e-9ba5ae3d83e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "63474b33-5325-4756-98f9-e95bd3ce4869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2['predicted_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6d47bea5-b004-4727-bd81-eef5f33a605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.iloc[inds][\"sentences source\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc53f8f-d120-44cb-bf3b-57ae98e2cfb9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 10 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1d15f538-452f-4b14-8501-9cbbedeb5b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inds = np.arange(0,10)\n",
    "# text = test_df.iloc[inds][\"sentences source\"]\n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2738300d-3d93-4cd8-8553-622dcc70c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = test_df.iloc[inds].copy()\n",
    "# df2['predicted_text'] = None\n",
    "\n",
    "# for i in range(text.shape[0]):\n",
    "#     with timeout(seconds=int(wait_timeout)):\n",
    "#         inputs = tokenizer(text[i], padding=\"longest\", return_tensors=\"pt\")\n",
    "#         output = model.generate(**inputs)\n",
    "#         output_text = tokenizer.decode(output[0], \n",
    "#                                         skip_special_tokens=skip_specials, \n",
    "#                                         clean_up_tokenization_spaces=True)\n",
    "#         output_text = str(output_text)\n",
    "#         df2['predicted_text'][i] = output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ca80f360-7433-4353-8361-9bddd599287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = output_dir_ + 's' + str(len(inds)) + ender + '.csv' \n",
    "# df2.to_csv(filename, index=False)\n",
    "# del df2\n",
    "# del output_text\n",
    "# del text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca29b72f-a82a-4793-97c8-a5f4ace2f8be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 20 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "08d6e1c7-6ab4-4a0f-aefd-2a37be006ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The model accurately reproduces tlie twin lobes see nin the Wilneretal.(2002) observations. as well as the exteided emission seen iu the lower resoutiou Hollandeal.(1998) observatious.'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = 23\n",
    "text = test_df.iloc[inds][\"sentences source\"]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8ba0f1e4-1809-46c4-ab9f-ca83f5d11fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "for i in range(23, 24):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "10711dee-a7c0-419a-889b-5a47c46e2aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aligned sentences source           The model accurately reproduces tlie twin lob...\n",
       "aligned sentences target           The model accurately reproduces th@e twin lob...\n",
       "sentences source                   The model accurately reproduces tlie twin lob...\n",
       "sentences target                   The model accurately reproduces the twin lobe...\n",
       "aligned sentences source types     WWW WWWWW WWWWWWWWWW WWWWWWWWWW WWWW WWWW WWW...\n",
       "aligned sentences target types     WWW WWWWW WWWWWWWWWW WWWWWWWWWW WW@W WWWW WWW...\n",
       "sentences source types             WWW WWWWW WWWWWWWWWW WWWWWWWWWW WWWW WWWW WWW...\n",
       "sentences target types             WWW WWWWW WWWWWWWWWW WWWWWWWWWW WWW WWWW WWWW...\n",
       "Name: 23, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = test_df.iloc[inds].copy()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "20a66416-46db-4f05-a2f0-17764b82e6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = test_df.iloc[inds].copy()\n",
    "df2['predicted_text'] = None\n",
    "\n",
    "# for i in range(23, 24):\n",
    "with timeout(seconds=int(wait_timeout)):\n",
    "    inputs = tokenizer(text[i], padding=\"longest\", return_tensors=\"pt\")\n",
    "    output = model.generate(**inputs)\n",
    "    output_text = tokenizer.decode(output[0], \n",
    "                                    skip_special_tokens=skip_specials, \n",
    "                                    clean_up_tokenization_spaces=True)\n",
    "    output_text = str(output_text)\n",
    "    df2['predicted_text'][i] = output_text\n",
    "# output_dir --> output_dir_ cuz conlficts with the snapshot     \n",
    "\n",
    "# filename = output_dir_ + 's' + str(40) + ender + '.csv' \n",
    "# df2.to_csv(filename, index=False)\n",
    "# del df2\n",
    "# del output_text\n",
    "# del text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "09e241a8-3f5d-47ca-a149-31af8ab3187c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The model accurately reproduces the twin lobes see in the \\\\citet{wilner02} observations, as well as the extended emission seen in the lower resolution \\\\citet{holland98} observations.'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8d030b18-e5a3-4251-8578-752ed413d1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aligned sentences source</th>\n",
       "      <th>aligned sentences target</th>\n",
       "      <th>sentences source</th>\n",
       "      <th>sentences target</th>\n",
       "      <th>aligned sentences source types</th>\n",
       "      <th>aligned sentences target types</th>\n",
       "      <th>sentences source types</th>\n",
       "      <th>sentences target types</th>\n",
       "      <th>predicted_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>This might reduce the rms scatter slightly.</td>\n",
       "      <td>This might reduce the rms scatter slightly.</td>\n",
       "      <td>This might reduce the rms scatter slightly.</td>\n",
       "      <td>This might reduce the rms scatter slightly.</td>\n",
       "      <td>WWWW WWWWW WWWWWW WWW WWW WWWWWWW WWWWWWWWW</td>\n",
       "      <td>WWWW WWWWW WWWWWW WWW WWW WWWWWWW WWWWWWWWW</td>\n",
       "      <td>WWWW WWWWW WWWWWW WWW WWW WWWWWWW WWWWWWWWW</td>\n",
       "      <td>WWWW WWWWW WWWWWW WWW WWW WWWWWWW WWWWWWWWW</td>\n",
       "      <td>This might reduce the rms scatter slightly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>We are grateful to Butler Burton. Carl IHeile...</td>\n",
       "      <td>We are grateful to Butler Burton, Carl @Heile...</td>\n",
       "      <td>We are grateful to Butler Burton. Carl IHeile...</td>\n",
       "      <td>We are grateful to Butler Burton, Carl Heiles...</td>\n",
       "      <td>WW WWW WWWWWWWW WW WWWWWW WWWWWWW WWWW WWWWWW...</td>\n",
       "      <td>WW WWW WWWWWWWW WW WWWWWW WWWWWWW WWWW @WWWWW...</td>\n",
       "      <td>WW WWW WWWWWWWW WW WWWWWW WWWWWWW WWWW WWWWWW...</td>\n",
       "      <td>WW WWW WWWWWWWW WW WWWWWW WWWWWWW WWWW WWWWWW...</td>\n",
       "      <td>We are grateful to Butler Burton, Carl Heiles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>In Eqn. ^^^^^^^(b) ^</td>\n",
       "      <td>In Eqn. \\ref{SDE}) )</td>\n",
       "      <td>In Eqn. (b)</td>\n",
       "      <td>In Eqn. \\ref{SDE}) )</td>\n",
       "      <td>WW WWWW ^^^^^^^WWW ^</td>\n",
       "      <td>WW WWWW RRRRRRRRRW W</td>\n",
       "      <td>WW WWWW WWW</td>\n",
       "      <td>WW WWWW RRRRRRRRRW W</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The model accurately reproduces tlie twin lob...</td>\n",
       "      <td>The model accurately reproduces th@e twin lob...</td>\n",
       "      <td>The model accurately reproduces tlie twin lob...</td>\n",
       "      <td>The model accurately reproduces the twin lobe...</td>\n",
       "      <td>WWW WWWWW WWWWWWWWWW WWWWWWWWWW WWWW WWWW WWW...</td>\n",
       "      <td>WWW WWWWW WWWWWWWWWW WWWWWWWWWW WW@W WWWW WWW...</td>\n",
       "      <td>WWW WWWWW WWWWWWWWWW WWWWWWWWWW WWWW WWWW WWW...</td>\n",
       "      <td>WWW WWWWW WWWWWWWWWW WWWWWWWWWW WWW WWWW WWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>It is possible, furthermore, that some of the...</td>\n",
       "      <td>It is possible, furthermore, that some of the...</td>\n",
       "      <td>It is possible, furthermore, that some of the...</td>\n",
       "      <td>It is possible, furthermore, that some of the...</td>\n",
       "      <td>WW WW WWWWWWWWW WWWWWWWWWWWW WWWW WWWW WW WWW...</td>\n",
       "      <td>WW WW WWWWWWWWW WWWWWWWWWWWW WWWW WWWW WW WWW...</td>\n",
       "      <td>WW WW WWWWWWWWW WWWWWWWWWWWW WWWW WWWW WW WWW...</td>\n",
       "      <td>WW WW WWWWWWWWW WWWWWWWWWWWW WWWW WWWW WW WWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>When the mass of such a shell reaches some cr...</td>\n",
       "      <td>When the mass of such a shell reaches some cr...</td>\n",
       "      <td>When the mass of such a shell reaches some cr...</td>\n",
       "      <td>When the mass of such a shell reaches some cr...</td>\n",
       "      <td>WWWW WWW WWWW WW WWWW W WWWWW WWWWWWW WWWW WW...</td>\n",
       "      <td>WWWW WWW WWWW WW WWWW W WWWWW WWWWWWW WWWW WW...</td>\n",
       "      <td>WWWW WWW WWWW WW WWWW W WWWWW WWWWWWW WWWW WW...</td>\n",
       "      <td>WWWW WWW WWWW WW WWWW W WWWWW WWWWWWW WWWW WW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>. It should also be noted that most of the upp...</td>\n",
       "      <td>@ It should also be noted that most of the upp...</td>\n",
       "      <td>. It should also be noted that most of the upp...</td>\n",
       "      <td>It should also be noted that most of the uppe...</td>\n",
       "      <td>W WW WWWWWW WWWW WW WWWWW WWWW WWWW WW WWW WWW...</td>\n",
       "      <td>@ WW WWWWWW WWWW WW WWWWW WWWW WWWW WW WWW WWW...</td>\n",
       "      <td>W WW WWWWWW WWWW WW WWWWW WWWW WWWW WW WWW WWW...</td>\n",
       "      <td>WW WWWWWW WWWW WW WWWWW WWWW WWWW WW WWW WWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>. There are also indications in nearby regious...</td>\n",
       "      <td>@ There are also indications in nearby regions...</td>\n",
       "      <td>. There are also indications in nearby regious...</td>\n",
       "      <td>There are also indications in nearby regions ...</td>\n",
       "      <td>W WWWWW WWW WWWW WWWWWWWWWWW WW WWWWWW WWWWWWW...</td>\n",
       "      <td>@ WWWWW WWW WWWW WWWWWWWWWWW WW WWWWWW WWWWWWW...</td>\n",
       "      <td>W WWWWW WWW WWWW WWWWWWWWWWW WW WWWWWW WWWWWWW...</td>\n",
       "      <td>WWWWW WWW WWWW WWWWWWWWWWW WW WWWWWW WWWWWWW ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Two of the remai^une three ^5a^S (adl617. 1d1...</td>\n",
       "      <td>Two of the remaining three stars (id1647, id1...</td>\n",
       "      <td>Two of the remaiune three 5aS (adl617. 1d1659...</td>\n",
       "      <td>Two of the remaining three stars (id1647, id1...</td>\n",
       "      <td>WWW WW WWW WWWWW^WWW WWWWW ^WW^W WWWWWWWW WWW...</td>\n",
       "      <td>WWW WW WWW WWWWWWWWW WWWWW WWWWW WWWWWWWW WWW...</td>\n",
       "      <td>WWW WW WWW WWWWWWWW WWWWW WWW WWWWWWWW WWWWWW...</td>\n",
       "      <td>WWW WW WWW WWWWWWWWW WWWWW WWWWW WWWWWWWW WWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>07. consistent with the predicted nature of he...</td>\n",
       "      <td>@@@ consistent with the predicted nature of he...</td>\n",
       "      <td>07. consistent with the predicted nature of he...</td>\n",
       "      <td>consistent with the predicted nature of heliu...</td>\n",
       "      <td>WWW WWWWWWWWWW WWWW WWW WWWWWWWWW WWWWWW WW WW...</td>\n",
       "      <td>@@@ WWWWWWWWWW WWWW WWW WWWWWWWWW WWWWWW WW WW...</td>\n",
       "      <td>WWW WWWWWWWWWW WWWW WWW WWWWWWWWW WWWWWW WW WW...</td>\n",
       "      <td>WWWWWWWWWW WWWW WWW WWWWWWWWW WWWWWW WW WWWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Onlv iu about ^^^^^^^data. acllition or subtr...</td>\n",
       "      <td>Only in about of the data, add@ition or subtr...</td>\n",
       "      <td>Onlv iu about data. acllition or subtraction ...</td>\n",
       "      <td>Only in about of the data, addition or subtra...</td>\n",
       "      <td>WWWW WW WWWWW ^^^^^^^WWWWW WWWWWWWWW WW WWWWW...</td>\n",
       "      <td>WWWW WW WWWWW WW WWW WWWWW WWW@WWWWW WW WWWWW...</td>\n",
       "      <td>WWWW WW WWWWW WWWWW WWWWWWWWW WW WWWWWWWWWWW ...</td>\n",
       "      <td>WWWW WW WWWWW WW WWW WWWWW WWWWWWWW WW WWWWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>We start a driven turbulence simulation witho...</td>\n",
       "      <td>We start a driven turbulence simulation witho...</td>\n",
       "      <td>We start a driven turbulence simulation witho...</td>\n",
       "      <td>We start a driven turbulence simulation witho...</td>\n",
       "      <td>WW WWWWW W WWWWWW WWWWWWWWWW WWWWWWWWWW WWWWW...</td>\n",
       "      <td>WW WWWWW W WWWWWW WWWWWWWWWW WWWWWWWWWW WWWWW...</td>\n",
       "      <td>WW WWWWW W WWWWWW WWWWWWWWWW WWWWWWWWWW WWWWW...</td>\n",
       "      <td>WW WWWWW W WWWWWW WWWWWWWWWW WWWWWWWWWW WWWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Despite considerable uncertainties 1n. the mo...</td>\n",
       "      <td>Despite considerable uncertainties in@ the mo...</td>\n",
       "      <td>Despite considerable uncertainties 1n. the mo...</td>\n",
       "      <td>Despite considerable uncertainties in the mod...</td>\n",
       "      <td>WWWWWWW WWWWWWWWWWWW WWWWWWWWWWWWW WWW WWW WW...</td>\n",
       "      <td>WWWWWWW WWWWWWWWWWWW WWWWWWWWWWWWW WW@ WWW WW...</td>\n",
       "      <td>WWWWWWW WWWWWWWWWWWW WWWWWWWWWWWWW WWW WWW WW...</td>\n",
       "      <td>WWWWWWW WWWWWWWWWWWW WWWWWWWWWWWWW WW WWW WWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Plots of ^(^^f,^^^.f5.f.)^ ave shown in figur...</td>\n",
       "      <td>Plots of $(t_a, t_b, t_c)$ are shown in figur...</td>\n",
       "      <td>Plots of (f,.f5.f.) ave shown in figure 5..</td>\n",
       "      <td>Plots of $(t_a, t_b, t_c)$ are shown in figur...</td>\n",
       "      <td>WWWWW WW ^I^^II^^^IIIIIII^ WWW WWWWW WW WWWWW...</td>\n",
       "      <td>WWWWW WW IIIIIIIIIIIIIIIII WWW WWWWW WW WWWWW...</td>\n",
       "      <td>WWWWW WW IIIIIIIIII WWW WWWWW WW WWWWWW RRW</td>\n",
       "      <td>WWWWW WW IIIIIIIIIIIIIIIII WWW WWWWW WW WWWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>In Figure l. we have shown a sample backgroun...</td>\n",
       "      <td>In Figure 1, we have shown a sample backgroun...</td>\n",
       "      <td>In Figure l. we have shown a sample backgroun...</td>\n",
       "      <td>In Figure 1, we have shown a sample backgroun...</td>\n",
       "      <td>WW WWWWWW WW WW WWWW WWWWW W WWWWWW WWWWWWWWW...</td>\n",
       "      <td>WW WWWWWW WW WW WWWW WWWWW W WWWWWW WWWWWWWWW...</td>\n",
       "      <td>WW WWWWWW WW WW WWWW WWWWW W WWWWWW WWWWWWWWW...</td>\n",
       "      <td>WW WWWWWW WW WW WWWW WWWWW W WWWWWW WWWWWWWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>. The properties of the objects that are relev...</td>\n",
       "      <td>@ The properties of the objects that are relev...</td>\n",
       "      <td>. The properties of the objects that are relev...</td>\n",
       "      <td>The properties of the objects that are releva...</td>\n",
       "      <td>W WWW WWWWWWWWWW WW WWW WWWWWWW WWWW WWW WWWWW...</td>\n",
       "      <td>@ WWW WWWWWWWWWW WW WWW WWWWWWW WWWW WWW WWWWW...</td>\n",
       "      <td>W WWW WWWWWWWWWW WW WWW WWWWWWW WWWW WWW WWWWW...</td>\n",
       "      <td>WWW WWWWWWWWWW WW WWW WWWWWWW WWWW WWW WWWWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Initially the variation in the accretion rate...</td>\n",
       "      <td>Initially the variation in the accretion rate...</td>\n",
       "      <td>Initially the variation in the accretion rate...</td>\n",
       "      <td>Initially the variation in the accretion rate...</td>\n",
       "      <td>WWWWWWWWW WWW WWWWWWWWW WW WWW WWWWWWWWW WWWW...</td>\n",
       "      <td>WWWWWWWWW WWW WWWWWWWWW WW WWW WWWWWWWWW WWWW...</td>\n",
       "      <td>WWWWWWWWW WWW WWWWWWWWW WW WWW WWWWWWWWW WWWW...</td>\n",
       "      <td>WWWWWWWWW WWW WWWWWWWWW WW WWW WWWWWWWWW WWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>We have then computed the median and confiden...</td>\n",
       "      <td>We have then computed the median and confiden...</td>\n",
       "      <td>We have then computed the median and confiden...</td>\n",
       "      <td>We have then computed the median and confiden...</td>\n",
       "      <td>WW WWWW WWWW WWWWWWWW WWW WWWWWW WWW WWWWWWWW...</td>\n",
       "      <td>WW WWWW WWWW WWWWWWWW WWW WWWWWW WWW WWWWWWWW...</td>\n",
       "      <td>WW WWWW WWWW WWWWWWWW WWW WWWWWW WWW WWWWWWWW...</td>\n",
       "      <td>WW WWWW WWWW WWWWWWWW WWW WWWWWW WWW WWWWWWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>This may be a result of accitional shocks and...</td>\n",
       "      <td>This may be a result of additional shocks and...</td>\n",
       "      <td>This may be a result of accitional shocks and...</td>\n",
       "      <td>This may be a result of additional shocks and...</td>\n",
       "      <td>WWWW WWW WW W WWWWWW WW WWWWWWWWWW WWWWWW WWW...</td>\n",
       "      <td>WWWW WWW WW W WWWWWW WW WWWWWWWWWW WWWWWW WWW...</td>\n",
       "      <td>WWWW WWW WW W WWWWWW WW WWWWWWWWWW WWWWWW WWW...</td>\n",
       "      <td>WWWW WWW WW W WWWWWW WW WWWWWWWWWW WWWWWW WWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>In Fig.</td>\n",
       "      <td>In Fig.</td>\n",
       "      <td>In Fig.</td>\n",
       "      <td>In Fig.</td>\n",
       "      <td>WW WWWW</td>\n",
       "      <td>WW WWWW</td>\n",
       "      <td>WW WWWW</td>\n",
       "      <td>WW WWWW</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             aligned sentences source  \\\n",
       "20        This might reduce the rms scatter slightly.   \n",
       "21   We are grateful to Butler Burton. Carl IHeile...   \n",
       "22                               In Eqn. ^^^^^^^(b) ^   \n",
       "23   The model accurately reproduces tlie twin lob...   \n",
       "24   It is possible, furthermore, that some of the...   \n",
       "25   When the mass of such a shell reaches some cr...   \n",
       "26  . It should also be noted that most of the upp...   \n",
       "27  . There are also indications in nearby regious...   \n",
       "28   Two of the remai^une three ^5a^S (adl617. 1d1...   \n",
       "29  07. consistent with the predicted nature of he...   \n",
       "30   Onlv iu about ^^^^^^^data. acllition or subtr...   \n",
       "31   We start a driven turbulence simulation witho...   \n",
       "32   Despite considerable uncertainties 1n. the mo...   \n",
       "33   Plots of ^(^^f,^^^.f5.f.)^ ave shown in figur...   \n",
       "34   In Figure l. we have shown a sample backgroun...   \n",
       "35  . The properties of the objects that are relev...   \n",
       "36   Initially the variation in the accretion rate...   \n",
       "37   We have then computed the median and confiden...   \n",
       "38   This may be a result of accitional shocks and...   \n",
       "39                                            In Fig.   \n",
       "\n",
       "                             aligned sentences target  \\\n",
       "20        This might reduce the rms scatter slightly.   \n",
       "21   We are grateful to Butler Burton, Carl @Heile...   \n",
       "22                               In Eqn. \\ref{SDE}) )   \n",
       "23   The model accurately reproduces th@e twin lob...   \n",
       "24   It is possible, furthermore, that some of the...   \n",
       "25   When the mass of such a shell reaches some cr...   \n",
       "26  @ It should also be noted that most of the upp...   \n",
       "27  @ There are also indications in nearby regions...   \n",
       "28   Two of the remaining three stars (id1647, id1...   \n",
       "29  @@@ consistent with the predicted nature of he...   \n",
       "30   Only in about of the data, add@ition or subtr...   \n",
       "31   We start a driven turbulence simulation witho...   \n",
       "32   Despite considerable uncertainties in@ the mo...   \n",
       "33   Plots of $(t_a, t_b, t_c)$ are shown in figur...   \n",
       "34   In Figure 1, we have shown a sample backgroun...   \n",
       "35  @ The properties of the objects that are relev...   \n",
       "36   Initially the variation in the accretion rate...   \n",
       "37   We have then computed the median and confiden...   \n",
       "38   This may be a result of additional shocks and...   \n",
       "39                                            In Fig.   \n",
       "\n",
       "                                     sentences source  \\\n",
       "20        This might reduce the rms scatter slightly.   \n",
       "21   We are grateful to Butler Burton. Carl IHeile...   \n",
       "22                                       In Eqn. (b)    \n",
       "23   The model accurately reproduces tlie twin lob...   \n",
       "24   It is possible, furthermore, that some of the...   \n",
       "25   When the mass of such a shell reaches some cr...   \n",
       "26  . It should also be noted that most of the upp...   \n",
       "27  . There are also indications in nearby regious...   \n",
       "28   Two of the remaiune three 5aS (adl617. 1d1659...   \n",
       "29  07. consistent with the predicted nature of he...   \n",
       "30   Onlv iu about data. acllition or subtraction ...   \n",
       "31   We start a driven turbulence simulation witho...   \n",
       "32   Despite considerable uncertainties 1n. the mo...   \n",
       "33        Plots of (f,.f5.f.) ave shown in figure 5..   \n",
       "34   In Figure l. we have shown a sample backgroun...   \n",
       "35  . The properties of the objects that are relev...   \n",
       "36   Initially the variation in the accretion rate...   \n",
       "37   We have then computed the median and confiden...   \n",
       "38   This may be a result of accitional shocks and...   \n",
       "39                                            In Fig.   \n",
       "\n",
       "                                     sentences target  \\\n",
       "20        This might reduce the rms scatter slightly.   \n",
       "21   We are grateful to Butler Burton, Carl Heiles...   \n",
       "22                               In Eqn. \\ref{SDE}) )   \n",
       "23   The model accurately reproduces the twin lobe...   \n",
       "24   It is possible, furthermore, that some of the...   \n",
       "25   When the mass of such a shell reaches some cr...   \n",
       "26   It should also be noted that most of the uppe...   \n",
       "27   There are also indications in nearby regions ...   \n",
       "28   Two of the remaining three stars (id1647, id1...   \n",
       "29   consistent with the predicted nature of heliu...   \n",
       "30   Only in about of the data, addition or subtra...   \n",
       "31   We start a driven turbulence simulation witho...   \n",
       "32   Despite considerable uncertainties in the mod...   \n",
       "33   Plots of $(t_a, t_b, t_c)$ are shown in figur...   \n",
       "34   In Figure 1, we have shown a sample backgroun...   \n",
       "35   The properties of the objects that are releva...   \n",
       "36   Initially the variation in the accretion rate...   \n",
       "37   We have then computed the median and confiden...   \n",
       "38   This may be a result of additional shocks and...   \n",
       "39                                            In Fig.   \n",
       "\n",
       "                       aligned sentences source types  \\\n",
       "20        WWWW WWWWW WWWWWW WWW WWW WWWWWWW WWWWWWWWW   \n",
       "21   WW WWW WWWWWWWW WW WWWWWW WWWWWWW WWWW WWWWWW...   \n",
       "22                               WW WWWW ^^^^^^^WWW ^   \n",
       "23   WWW WWWWW WWWWWWWWWW WWWWWWWWWW WWWW WWWW WWW...   \n",
       "24   WW WW WWWWWWWWW WWWWWWWWWWWW WWWW WWWW WW WWW...   \n",
       "25   WWWW WWW WWWW WW WWWW W WWWWW WWWWWWW WWWW WW...   \n",
       "26  W WW WWWWWW WWWW WW WWWWW WWWW WWWW WW WWW WWW...   \n",
       "27  W WWWWW WWW WWWW WWWWWWWWWWW WW WWWWWW WWWWWWW...   \n",
       "28   WWW WW WWW WWWWW^WWW WWWWW ^WW^W WWWWWWWW WWW...   \n",
       "29  WWW WWWWWWWWWW WWWW WWW WWWWWWWWW WWWWWW WW WW...   \n",
       "30   WWWW WW WWWWW ^^^^^^^WWWWW WWWWWWWWW WW WWWWW...   \n",
       "31   WW WWWWW W WWWWWW WWWWWWWWWW WWWWWWWWWW WWWWW...   \n",
       "32   WWWWWWW WWWWWWWWWWWW WWWWWWWWWWWWW WWW WWW WW...   \n",
       "33   WWWWW WW ^I^^II^^^IIIIIII^ WWW WWWWW WW WWWWW...   \n",
       "34   WW WWWWWW WW WW WWWW WWWWW W WWWWWW WWWWWWWWW...   \n",
       "35  W WWW WWWWWWWWWW WW WWW WWWWWWW WWWW WWW WWWWW...   \n",
       "36   WWWWWWWWW WWW WWWWWWWWW WW WWW WWWWWWWWW WWWW...   \n",
       "37   WW WWWW WWWW WWWWWWWW WWW WWWWWW WWW WWWWWWWW...   \n",
       "38   WWWW WWW WW W WWWWWW WW WWWWWWWWWW WWWWWW WWW...   \n",
       "39                                            WW WWWW   \n",
       "\n",
       "                       aligned sentences target types  \\\n",
       "20        WWWW WWWWW WWWWWW WWW WWW WWWWWWW WWWWWWWWW   \n",
       "21   WW WWW WWWWWWWW WW WWWWWW WWWWWWW WWWW @WWWWW...   \n",
       "22                               WW WWWW RRRRRRRRRW W   \n",
       "23   WWW WWWWW WWWWWWWWWW WWWWWWWWWW WW@W WWWW WWW...   \n",
       "24   WW WW WWWWWWWWW WWWWWWWWWWWW WWWW WWWW WW WWW...   \n",
       "25   WWWW WWW WWWW WW WWWW W WWWWW WWWWWWW WWWW WW...   \n",
       "26  @ WW WWWWWW WWWW WW WWWWW WWWW WWWW WW WWW WWW...   \n",
       "27  @ WWWWW WWW WWWW WWWWWWWWWWW WW WWWWWW WWWWWWW...   \n",
       "28   WWW WW WWW WWWWWWWWW WWWWW WWWWW WWWWWWWW WWW...   \n",
       "29  @@@ WWWWWWWWWW WWWW WWW WWWWWWWWW WWWWWW WW WW...   \n",
       "30   WWWW WW WWWWW WW WWW WWWWW WWW@WWWWW WW WWWWW...   \n",
       "31   WW WWWWW W WWWWWW WWWWWWWWWW WWWWWWWWWW WWWWW...   \n",
       "32   WWWWWWW WWWWWWWWWWWW WWWWWWWWWWWWW WW@ WWW WW...   \n",
       "33   WWWWW WW IIIIIIIIIIIIIIIII WWW WWWWW WW WWWWW...   \n",
       "34   WW WWWWWW WW WW WWWW WWWWW W WWWWWW WWWWWWWWW...   \n",
       "35  @ WWW WWWWWWWWWW WW WWW WWWWWWW WWWW WWW WWWWW...   \n",
       "36   WWWWWWWWW WWW WWWWWWWWW WW WWW WWWWWWWWW WWWW...   \n",
       "37   WW WWWW WWWW WWWWWWWW WWW WWWWWW WWW WWWWWWWW...   \n",
       "38   WWWW WWW WW W WWWWWW WW WWWWWWWWWW WWWWWW WWW...   \n",
       "39                                            WW WWWW   \n",
       "\n",
       "                               sentences source types  \\\n",
       "20        WWWW WWWWW WWWWWW WWW WWW WWWWWWW WWWWWWWWW   \n",
       "21   WW WWW WWWWWWWW WW WWWWWW WWWWWWW WWWW WWWWWW...   \n",
       "22                                       WW WWWW WWW    \n",
       "23   WWW WWWWW WWWWWWWWWW WWWWWWWWWW WWWW WWWW WWW...   \n",
       "24   WW WW WWWWWWWWW WWWWWWWWWWWW WWWW WWWW WW WWW...   \n",
       "25   WWWW WWW WWWW WW WWWW W WWWWW WWWWWWW WWWW WW...   \n",
       "26  W WW WWWWWW WWWW WW WWWWW WWWW WWWW WW WWW WWW...   \n",
       "27  W WWWWW WWW WWWW WWWWWWWWWWW WW WWWWWW WWWWWWW...   \n",
       "28   WWW WW WWW WWWWWWWW WWWWW WWW WWWWWWWW WWWWWW...   \n",
       "29  WWW WWWWWWWWWW WWWW WWW WWWWWWWWW WWWWWW WW WW...   \n",
       "30   WWWW WW WWWWW WWWWW WWWWWWWWW WW WWWWWWWWWWW ...   \n",
       "31   WW WWWWW W WWWWWW WWWWWWWWWW WWWWWWWWWW WWWWW...   \n",
       "32   WWWWWWW WWWWWWWWWWWW WWWWWWWWWWWWW WWW WWW WW...   \n",
       "33        WWWWW WW IIIIIIIIII WWW WWWWW WW WWWWWW RRW   \n",
       "34   WW WWWWWW WW WW WWWW WWWWW W WWWWWW WWWWWWWWW...   \n",
       "35  W WWW WWWWWWWWWW WW WWW WWWWWWW WWWW WWW WWWWW...   \n",
       "36   WWWWWWWWW WWW WWWWWWWWW WW WWW WWWWWWWWW WWWW...   \n",
       "37   WW WWWW WWWW WWWWWWWW WWW WWWWWW WWW WWWWWWWW...   \n",
       "38   WWWW WWW WW W WWWWWW WW WWWWWWWWWW WWWWWW WWW...   \n",
       "39                                            WW WWWW   \n",
       "\n",
       "                               sentences target types  \\\n",
       "20        WWWW WWWWW WWWWWW WWW WWW WWWWWWW WWWWWWWWW   \n",
       "21   WW WWW WWWWWWWW WW WWWWWW WWWWWWW WWWW WWWWWW...   \n",
       "22                               WW WWWW RRRRRRRRRW W   \n",
       "23   WWW WWWWW WWWWWWWWWW WWWWWWWWWW WWW WWWW WWWW...   \n",
       "24   WW WW WWWWWWWWW WWWWWWWWWWWW WWWW WWWW WW WWW...   \n",
       "25   WWWW WWW WWWW WW WWWW W WWWWW WWWWWWW WWWW WW...   \n",
       "26   WW WWWWWW WWWW WW WWWWW WWWW WWWW WW WWW WWWW...   \n",
       "27   WWWWW WWW WWWW WWWWWWWWWWW WW WWWWWW WWWWWWW ...   \n",
       "28   WWW WW WWW WWWWWWWWW WWWWW WWWWW WWWWWWWW WWW...   \n",
       "29   WWWWWWWWWW WWWW WWW WWWWWWWWW WWWWWW WW WWWWW...   \n",
       "30   WWWW WW WWWWW WW WWW WWWWW WWWWWWWW WW WWWWWW...   \n",
       "31   WW WWWWW W WWWWWW WWWWWWWWWW WWWWWWWWWW WWWWW...   \n",
       "32   WWWWWWW WWWWWWWWWWWW WWWWWWWWWWWWW WW WWW WWW...   \n",
       "33   WWWWW WW IIIIIIIIIIIIIIIII WWW WWWWW WW WWWWW...   \n",
       "34   WW WWWWWW WW WW WWWW WWWWW W WWWWWW WWWWWWWWW...   \n",
       "35   WWW WWWWWWWWWW WW WWW WWWWWWW WWWW WWW WWWWWW...   \n",
       "36   WWWWWWWWW WWW WWWWWWWWW WW WWW WWWWWWWWW WWWW...   \n",
       "37   WW WWWW WWWW WWWWWWWW WWW WWWWWW WWW WWWWWWWW...   \n",
       "38   WWWW WWW WW W WWWWWW WW WWWWWWWWWW WWWWWW WWW...   \n",
       "39                                            WW WWWW   \n",
       "\n",
       "                                       predicted_text  \n",
       "20        This might reduce the rms scatter slightly.  \n",
       "21   We are grateful to Butler Burton, Carl Heiles...  \n",
       "22                                               None  \n",
       "23                                               None  \n",
       "24                                               None  \n",
       "25                                               None  \n",
       "26                                               None  \n",
       "27                                               None  \n",
       "28                                               None  \n",
       "29                                               None  \n",
       "30                                               None  \n",
       "31                                               None  \n",
       "32                                               None  \n",
       "33                                               None  \n",
       "34                                               None  \n",
       "35                                               None  \n",
       "36                                               None  \n",
       "37                                               None  \n",
       "38                                               None  \n",
       "39                                               None  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5649bc78-e34b-42d8-b80d-56bbeb09f70f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### next 20 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17d4281-cc98-4c2a-a2fd-13ab89785e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07fd7ac-df2a-42b1-a205-269107961fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inds = np.arange(20,40)\n",
    "# text = test_df.iloc[inds][\"sentences source\"]\n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fdd751-4866-4b55-b809-8bb4c936cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. timeout --> solution not stable\n",
    "# 2. save it as error or nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0457e42f-e883-4831-ac1d-e741400ec25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inds = np.arange(0,len(test_df))\n",
    "# text = test_df.iloc[inds][\"sentences source\"]\n",
    "# text[9990:len(test_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2899aea3-be87-4722-991b-fa6a5244c93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        A histogram of the Va /slope for dwarf irregu...\n",
       "1        Observations were carried out. using a log of...\n",
       "2        Compared to a smooth polynomial. the flat fie...\n",
       "3                          2006) confirmed. lis scenario.\n",
       "4        Thus. slieht differences in ihe Â©C'a value of...\n",
       "                              ...                        \n",
       "9995     TIe X-ray spectra obtaiied with previous low-...\n",
       "9996     This variation stems primarily from the initi...\n",
       "9997     Leroyetal.(2008) aud Dieielet used the 21 fux...\n",
       "9998     Making use of the approximation that p=X/H gi...\n",
       "9999           This is qualitatively consistent (see Fig.\n",
       "Name: sentences source, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = np.arange(0,len(test_df))\n",
    "text = test_df.iloc[inds][\"sentences source\"]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb02a8-5750-4d79-afb4-52b7fd39442a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 : error or timeout in model\n",
      "372 : error or timeout in model\n",
      "525 : error or timeout in model\n",
      "614 : error or timeout in model\n",
      "654 : error or timeout in model\n",
      "662 : error or timeout in model\n",
      "668 : error or timeout in model\n",
      "697 : error or timeout in model\n",
      "1022 : error or timeout in model\n",
      "1036 : error or timeout in model\n",
      "1085 : error or timeout in model\n",
      "1149 : error or timeout in model\n",
      "1422 : error or timeout in model\n",
      "1655 : error or timeout in model\n",
      "1908 : error or timeout in model\n",
      "1910 : error or timeout in model\n",
      "1952 : error or timeout in model\n",
      "2315 : error or timeout in model\n",
      "2347 : error or timeout in model\n",
      "2601 : error or timeout in model\n",
      "2684 : error or timeout in model\n",
      "2794 : error or timeout in model\n",
      "2812 : error or timeout in model\n"
     ]
    }
   ],
   "source": [
    "df2 = test_df.iloc[inds].copy()\n",
    "df2['predicted_text'] = None\n",
    "\n",
    "for i in range(text.shape[0]):\n",
    "    if i%100 == 0:\n",
    "        filename = output_dir_ + 's' + str(i) + ender + '.csv' \n",
    "        df2.to_csv(filename, index=False)\n",
    "    try: \n",
    "        with timeout(seconds=int(wait_timeout)):\n",
    "            inputs = tokenizer(text[i], padding=\"longest\", return_tensors=\"pt\")\n",
    "            output = model.generate(**inputs)\n",
    "            output_text = tokenizer.decode(output[0], \n",
    "                                            skip_special_tokens=skip_specials, \n",
    "                                            clean_up_tokenization_spaces=True)\n",
    "            output_text = str(output_text)\n",
    "    except:\n",
    "        #import sys; sys.exit()\n",
    "        print(i, ': error or timeout in model')\n",
    "        output_text = np.nan\n",
    "        err = True\n",
    "    df2['predicted_text'][i] = output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63d6394-43d1-4e79-b63c-bcc1837f7f72",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Options --> do things in parallel instead of series --> gpu \n",
    "## Theory --> subset of 16 --> 10 and 6\n",
    "## Inference for each individual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e63799c-5852-4053-8dd1-ce7b134be811",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[990:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9636715c-0692-4db2-b6a5-5ee0f38f297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df2[9990:len(test_df)])\n",
    "filename = output_dir_ + 's' + str(len(inds)) + ender + '.csv' \n",
    "df2.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe5b0d3-83b4-4eb5-84b9-561f557b6e4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c227674c-98f5-4c09-be30-022fde3ffb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = test_df.iloc[inds].copy()\n",
    "# df2['predicted_text'] = None\n",
    "\n",
    "# try: \n",
    "#     for i in range(text.shape[0]):\n",
    "#         with timeout(seconds=int(wait_timeout)):\n",
    "#             inputs = tokenizer(text[i], padding=\"longest\", return_tensors=\"pt\")\n",
    "#             output = model.generate(**inputs)\n",
    "#             output_text = tokenizer.decode(output[0], \n",
    "#                                             skip_special_tokens=skip_specials, \n",
    "#                                             clean_up_tokenization_spaces=True)\n",
    "#             output_text = str(output_text)\n",
    "# except:\n",
    "#         #import sys; sys.exit()\n",
    "#         print(ind, ': error or timeout in model')\n",
    "#         output_text = np.nan\n",
    "#         err = True\n",
    "# df2['predicted_text'][i] = output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9532710-fe0f-412c-8d04-59ce064126c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' There are reasons to question whether the distribution of dark matter in galactic halos has to be regarded as smooth on all scales.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cab7148-90db-40d8-9079-fdc3ac2ce9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with timeout(seconds=int(wait_timeout)):\n",
    "#     inputs = tokenizer(text[i+20], padding=\"longest\", return_tensors=\"pt\")\n",
    "#     output = model.generate(**inputs)\n",
    "#     output_text = tokenizer.decode(output[0], \n",
    "#                                     skip_special_tokens=skip_specials, \n",
    "#                                     clean_up_tokenization_spaces=True)\n",
    "#     output_text = str(output_text)\n",
    "#     df2['predicted_text'][i+20] = output_text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "89331d91-7001-4f6d-af89-670e5e7e1abf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "Timeout",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1803785/944218005.py\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"longest\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         output_text = tokenizer.decode(output[0], \n\u001b[1;32m      9\u001b[0m                                         \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_specials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/BIOE-488-v2/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/BIOE-488-v2/lib/python3.9/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;31m# 10. run greedy search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m             return self.greedy_search(\n\u001b[0m\u001b[1;32m   1174\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/BIOE-488-v2/lib/python3.9/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   1470\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/BIOE-488-v2/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/BIOE-488-v2/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1616\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1617\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/BIOE-488-v2/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/BIOE-488-v2/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1009\u001b[0m                 )\n\u001b[1;32m   1010\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1012\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/BIOE-488-v2/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/BIOE-488-v2/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    644\u001b[0m             \u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         self_attention_outputs = self.layer[0](\n\u001b[0m\u001b[1;32m    647\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/BIOE-488-v2/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/BIOE-488-v2/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    551\u001b[0m     ):\n\u001b[1;32m    552\u001b[0m         \u001b[0mnormed_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         attention_output = self.SelfAttention(\n\u001b[0m\u001b[1;32m    554\u001b[0m             \u001b[0mnormed_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/BIOE-488-v2/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/BIOE-488-v2/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    500\u001b[0m                     \u001b[0mposition_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m                 \u001b[0mposition_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;31m# if key and values are already calculated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/BIOE-488-v2/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mcompute_bias\u001b[0;34m(self, query_length, key_length)\u001b[0m\n\u001b[1;32m    408\u001b[0m         )[None, :]\n\u001b[1;32m    409\u001b[0m         \u001b[0mrelative_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory_position\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcontext_position\u001b[0m  \u001b[0;31m# shape (query_length, key_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         relative_position_bucket = self._relative_position_bucket(\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0mrelative_position\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# shape (query_length, key_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mbidirectional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_decoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/BIOE-488-v2/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36m_relative_position_bucket\u001b[0;34m(relative_position, bidirectional, num_buckets, max_distance)\u001b[0m\n\u001b[1;32m    396\u001b[0m         )\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0mrelative_buckets\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative_postion_if_large\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrelative_buckets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1803785/3281125435.py\u001b[0m in \u001b[0;36mhandle_timeout\u001b[0;34m(self, signum, frame)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhandle_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGALRM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: Timeout"
     ]
    }
   ],
   "source": [
    "# df2 = test_df.iloc[inds].copy()\n",
    "# df2['predicted_text'] = None\n",
    "\n",
    "# for i in range(text.shape[0]):\n",
    "#     with timeout(seconds=int(wait_timeout)):\n",
    "#         inputs = tokenizer(text[i+20], padding=\"longest\", return_tensors=\"pt\")\n",
    "#         output = model.generate(**inputs)\n",
    "#         output_text = tokenizer.decode(output[0], \n",
    "#                                         skip_special_tokens=skip_specials, \n",
    "#                                         clean_up_tokenization_spaces=True)\n",
    "#         output_text = str(output_text)\n",
    "#         df2['predicted_text'][i+20] = output_text\n",
    "        \n",
    "# filename = output_dir_ + 's' + str(len(inds)) + ender + '.csv' \n",
    "# df2.to_csv(filename, index=False)\n",
    "# del df2\n",
    "# del output_text\n",
    "# del text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cc0d1079-1b1f-4947-b982-a59c546ad32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aligned sentences source</th>\n",
       "      <th>aligned sentences target</th>\n",
       "      <th>sentences source</th>\n",
       "      <th>sentences target</th>\n",
       "      <th>aligned sentences source types</th>\n",
       "      <th>aligned sentences target types</th>\n",
       "      <th>sentences source types</th>\n",
       "      <th>sentences target types</th>\n",
       "      <th>predicted_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>This might reduce the rms scatter slightly.</td>\n",
       "      <td>This might reduce the rms scatter slightly.</td>\n",
       "      <td>This might reduce the rms scatter slightly.</td>\n",
       "      <td>This might reduce the rms scatter slightly.</td>\n",
       "      <td>WWWW WWWWW WWWWWW WWW WWW WWWWWWW WWWWWWWWW</td>\n",
       "      <td>WWWW WWWWW WWWWWW WWW WWW WWWWWWW WWWWWWWWW</td>\n",
       "      <td>WWWW WWWWW WWWWWW WWW WWW WWWWWWW WWWWWWWWW</td>\n",
       "      <td>WWWW WWWWW WWWWWW WWW WWW WWWWWWW WWWWWWWWW</td>\n",
       "      <td>This might reduce the rms scatter slightly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>We are grateful to Butler Burton. Carl IHeile...</td>\n",
       "      <td>We are grateful to Butler Burton, Carl @Heile...</td>\n",
       "      <td>We are grateful to Butler Burton. Carl IHeile...</td>\n",
       "      <td>We are grateful to Butler Burton, Carl Heiles...</td>\n",
       "      <td>WW WWW WWWWWWWW WW WWWWWW WWWWWWW WWWW WWWWWW...</td>\n",
       "      <td>WW WWW WWWWWWWW WW WWWWWW WWWWWWW WWWW @WWWWW...</td>\n",
       "      <td>WW WWW WWWWWWWW WW WWWWWW WWWWWWW WWWW WWWWWW...</td>\n",
       "      <td>WW WWW WWWWWWWW WW WWWWWW WWWWWWW WWWW WWWWWW...</td>\n",
       "      <td>We are grateful to Butler Burton, Carl Heiles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>In Eqn. ^^^^^^^(b) ^</td>\n",
       "      <td>In Eqn. \\ref{SDE}) )</td>\n",
       "      <td>In Eqn. (b)</td>\n",
       "      <td>In Eqn. \\ref{SDE}) )</td>\n",
       "      <td>WW WWWW ^^^^^^^WWW ^</td>\n",
       "      <td>WW WWWW RRRRRRRRRW W</td>\n",
       "      <td>WW WWWW WWW</td>\n",
       "      <td>WW WWWW RRRRRRRRRW W</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The model accurately reproduces tlie twin lob...</td>\n",
       "      <td>The model accurately reproduces th@e twin lob...</td>\n",
       "      <td>The model accurately reproduces tlie twin lob...</td>\n",
       "      <td>The model accurately reproduces the twin lobe...</td>\n",
       "      <td>WWW WWWWW WWWWWWWWWW WWWWWWWWWW WWWW WWWW WWW...</td>\n",
       "      <td>WWW WWWWW WWWWWWWWWW WWWWWWWWWW WW@W WWWW WWW...</td>\n",
       "      <td>WWW WWWWW WWWWWWWWWW WWWWWWWWWW WWWW WWWW WWW...</td>\n",
       "      <td>WWW WWWWW WWWWWWWWWW WWWWWWWWWW WWW WWWW WWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>It is possible, furthermore, that some of the...</td>\n",
       "      <td>It is possible, furthermore, that some of the...</td>\n",
       "      <td>It is possible, furthermore, that some of the...</td>\n",
       "      <td>It is possible, furthermore, that some of the...</td>\n",
       "      <td>WW WW WWWWWWWWW WWWWWWWWWWWW WWWW WWWW WW WWW...</td>\n",
       "      <td>WW WW WWWWWWWWW WWWWWWWWWWWW WWWW WWWW WW WWW...</td>\n",
       "      <td>WW WW WWWWWWWWW WWWWWWWWWWWW WWWW WWWW WW WWW...</td>\n",
       "      <td>WW WW WWWWWWWWW WWWWWWWWWWWW WWWW WWWW WW WWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>When the mass of such a shell reaches some cr...</td>\n",
       "      <td>When the mass of such a shell reaches some cr...</td>\n",
       "      <td>When the mass of such a shell reaches some cr...</td>\n",
       "      <td>When the mass of such a shell reaches some cr...</td>\n",
       "      <td>WWWW WWW WWWW WW WWWW W WWWWW WWWWWWW WWWW WW...</td>\n",
       "      <td>WWWW WWW WWWW WW WWWW W WWWWW WWWWWWW WWWW WW...</td>\n",
       "      <td>WWWW WWW WWWW WW WWWW W WWWWW WWWWWWW WWWW WW...</td>\n",
       "      <td>WWWW WWW WWWW WW WWWW W WWWWW WWWWWWW WWWW WW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>. It should also be noted that most of the upp...</td>\n",
       "      <td>@ It should also be noted that most of the upp...</td>\n",
       "      <td>. It should also be noted that most of the upp...</td>\n",
       "      <td>It should also be noted that most of the uppe...</td>\n",
       "      <td>W WW WWWWWW WWWW WW WWWWW WWWW WWWW WW WWW WWW...</td>\n",
       "      <td>@ WW WWWWWW WWWW WW WWWWW WWWW WWWW WW WWW WWW...</td>\n",
       "      <td>W WW WWWWWW WWWW WW WWWWW WWWW WWWW WW WWW WWW...</td>\n",
       "      <td>WW WWWWWW WWWW WW WWWWW WWWW WWWW WW WWW WWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>. There are also indications in nearby regious...</td>\n",
       "      <td>@ There are also indications in nearby regions...</td>\n",
       "      <td>. There are also indications in nearby regious...</td>\n",
       "      <td>There are also indications in nearby regions ...</td>\n",
       "      <td>W WWWWW WWW WWWW WWWWWWWWWWW WW WWWWWW WWWWWWW...</td>\n",
       "      <td>@ WWWWW WWW WWWW WWWWWWWWWWW WW WWWWWW WWWWWWW...</td>\n",
       "      <td>W WWWWW WWW WWWW WWWWWWWWWWW WW WWWWWW WWWWWWW...</td>\n",
       "      <td>WWWWW WWW WWWW WWWWWWWWWWW WW WWWWWW WWWWWWW ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Two of the remai^une three ^5a^S (adl617. 1d1...</td>\n",
       "      <td>Two of the remaining three stars (id1647, id1...</td>\n",
       "      <td>Two of the remaiune three 5aS (adl617. 1d1659...</td>\n",
       "      <td>Two of the remaining three stars (id1647, id1...</td>\n",
       "      <td>WWW WW WWW WWWWW^WWW WWWWW ^WW^W WWWWWWWW WWW...</td>\n",
       "      <td>WWW WW WWW WWWWWWWWW WWWWW WWWWW WWWWWWWW WWW...</td>\n",
       "      <td>WWW WW WWW WWWWWWWW WWWWW WWW WWWWWWWW WWWWWW...</td>\n",
       "      <td>WWW WW WWW WWWWWWWWW WWWWW WWWWW WWWWWWWW WWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>07. consistent with the predicted nature of he...</td>\n",
       "      <td>@@@ consistent with the predicted nature of he...</td>\n",
       "      <td>07. consistent with the predicted nature of he...</td>\n",
       "      <td>consistent with the predicted nature of heliu...</td>\n",
       "      <td>WWW WWWWWWWWWW WWWW WWW WWWWWWWWW WWWWWW WW WW...</td>\n",
       "      <td>@@@ WWWWWWWWWW WWWW WWW WWWWWWWWW WWWWWW WW WW...</td>\n",
       "      <td>WWW WWWWWWWWWW WWWW WWW WWWWWWWWW WWWWWW WW WW...</td>\n",
       "      <td>WWWWWWWWWW WWWW WWW WWWWWWWWW WWWWWW WW WWWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Onlv iu about ^^^^^^^data. acllition or subtr...</td>\n",
       "      <td>Only in about of the data, add@ition or subtr...</td>\n",
       "      <td>Onlv iu about data. acllition or subtraction ...</td>\n",
       "      <td>Only in about of the data, addition or subtra...</td>\n",
       "      <td>WWWW WW WWWWW ^^^^^^^WWWWW WWWWWWWWW WW WWWWW...</td>\n",
       "      <td>WWWW WW WWWWW WW WWW WWWWW WWW@WWWWW WW WWWWW...</td>\n",
       "      <td>WWWW WW WWWWW WWWWW WWWWWWWWW WW WWWWWWWWWWW ...</td>\n",
       "      <td>WWWW WW WWWWW WW WWW WWWWW WWWWWWWW WW WWWWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>We start a driven turbulence simulation witho...</td>\n",
       "      <td>We start a driven turbulence simulation witho...</td>\n",
       "      <td>We start a driven turbulence simulation witho...</td>\n",
       "      <td>We start a driven turbulence simulation witho...</td>\n",
       "      <td>WW WWWWW W WWWWWW WWWWWWWWWW WWWWWWWWWW WWWWW...</td>\n",
       "      <td>WW WWWWW W WWWWWW WWWWWWWWWW WWWWWWWWWW WWWWW...</td>\n",
       "      <td>WW WWWWW W WWWWWW WWWWWWWWWW WWWWWWWWWW WWWWW...</td>\n",
       "      <td>WW WWWWW W WWWWWW WWWWWWWWWW WWWWWWWWWW WWWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Despite considerable uncertainties 1n. the mo...</td>\n",
       "      <td>Despite considerable uncertainties in@ the mo...</td>\n",
       "      <td>Despite considerable uncertainties 1n. the mo...</td>\n",
       "      <td>Despite considerable uncertainties in the mod...</td>\n",
       "      <td>WWWWWWW WWWWWWWWWWWW WWWWWWWWWWWWW WWW WWW WW...</td>\n",
       "      <td>WWWWWWW WWWWWWWWWWWW WWWWWWWWWWWWW WW@ WWW WW...</td>\n",
       "      <td>WWWWWWW WWWWWWWWWWWW WWWWWWWWWWWWW WWW WWW WW...</td>\n",
       "      <td>WWWWWWW WWWWWWWWWWWW WWWWWWWWWWWWW WW WWW WWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Plots of ^(^^f,^^^.f5.f.)^ ave shown in figur...</td>\n",
       "      <td>Plots of $(t_a, t_b, t_c)$ are shown in figur...</td>\n",
       "      <td>Plots of (f,.f5.f.) ave shown in figure 5..</td>\n",
       "      <td>Plots of $(t_a, t_b, t_c)$ are shown in figur...</td>\n",
       "      <td>WWWWW WW ^I^^II^^^IIIIIII^ WWW WWWWW WW WWWWW...</td>\n",
       "      <td>WWWWW WW IIIIIIIIIIIIIIIII WWW WWWWW WW WWWWW...</td>\n",
       "      <td>WWWWW WW IIIIIIIIII WWW WWWWW WW WWWWWW RRW</td>\n",
       "      <td>WWWWW WW IIIIIIIIIIIIIIIII WWW WWWWW WW WWWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>In Figure l. we have shown a sample backgroun...</td>\n",
       "      <td>In Figure 1, we have shown a sample backgroun...</td>\n",
       "      <td>In Figure l. we have shown a sample backgroun...</td>\n",
       "      <td>In Figure 1, we have shown a sample backgroun...</td>\n",
       "      <td>WW WWWWWW WW WW WWWW WWWWW W WWWWWW WWWWWWWWW...</td>\n",
       "      <td>WW WWWWWW WW WW WWWW WWWWW W WWWWWW WWWWWWWWW...</td>\n",
       "      <td>WW WWWWWW WW WW WWWW WWWWW W WWWWWW WWWWWWWWW...</td>\n",
       "      <td>WW WWWWWW WW WW WWWW WWWWW W WWWWWW WWWWWWWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>. The properties of the objects that are relev...</td>\n",
       "      <td>@ The properties of the objects that are relev...</td>\n",
       "      <td>. The properties of the objects that are relev...</td>\n",
       "      <td>The properties of the objects that are releva...</td>\n",
       "      <td>W WWW WWWWWWWWWW WW WWW WWWWWWW WWWW WWW WWWWW...</td>\n",
       "      <td>@ WWW WWWWWWWWWW WW WWW WWWWWWW WWWW WWW WWWWW...</td>\n",
       "      <td>W WWW WWWWWWWWWW WW WWW WWWWWWW WWWW WWW WWWWW...</td>\n",
       "      <td>WWW WWWWWWWWWW WW WWW WWWWWWW WWWW WWW WWWWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Initially the variation in the accretion rate...</td>\n",
       "      <td>Initially the variation in the accretion rate...</td>\n",
       "      <td>Initially the variation in the accretion rate...</td>\n",
       "      <td>Initially the variation in the accretion rate...</td>\n",
       "      <td>WWWWWWWWW WWW WWWWWWWWW WW WWW WWWWWWWWW WWWW...</td>\n",
       "      <td>WWWWWWWWW WWW WWWWWWWWW WW WWW WWWWWWWWW WWWW...</td>\n",
       "      <td>WWWWWWWWW WWW WWWWWWWWW WW WWW WWWWWWWWW WWWW...</td>\n",
       "      <td>WWWWWWWWW WWW WWWWWWWWW WW WWW WWWWWWWWW WWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>We have then computed the median and confiden...</td>\n",
       "      <td>We have then computed the median and confiden...</td>\n",
       "      <td>We have then computed the median and confiden...</td>\n",
       "      <td>We have then computed the median and confiden...</td>\n",
       "      <td>WW WWWW WWWW WWWWWWWW WWW WWWWWW WWW WWWWWWWW...</td>\n",
       "      <td>WW WWWW WWWW WWWWWWWW WWW WWWWWW WWW WWWWWWWW...</td>\n",
       "      <td>WW WWWW WWWW WWWWWWWW WWW WWWWWW WWW WWWWWWWW...</td>\n",
       "      <td>WW WWWW WWWW WWWWWWWW WWW WWWWWW WWW WWWWWWWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>This may be a result of accitional shocks and...</td>\n",
       "      <td>This may be a result of additional shocks and...</td>\n",
       "      <td>This may be a result of accitional shocks and...</td>\n",
       "      <td>This may be a result of additional shocks and...</td>\n",
       "      <td>WWWW WWW WW W WWWWWW WW WWWWWWWWWW WWWWWW WWW...</td>\n",
       "      <td>WWWW WWW WW W WWWWWW WW WWWWWWWWWW WWWWWW WWW...</td>\n",
       "      <td>WWWW WWW WW W WWWWWW WW WWWWWWWWWW WWWWWW WWW...</td>\n",
       "      <td>WWWW WWW WW W WWWWWW WW WWWWWWWWWW WWWWWW WWW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>In Fig.</td>\n",
       "      <td>In Fig.</td>\n",
       "      <td>In Fig.</td>\n",
       "      <td>In Fig.</td>\n",
       "      <td>WW WWWW</td>\n",
       "      <td>WW WWWW</td>\n",
       "      <td>WW WWWW</td>\n",
       "      <td>WW WWWW</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             aligned sentences source  \\\n",
       "20        This might reduce the rms scatter slightly.   \n",
       "21   We are grateful to Butler Burton. Carl IHeile...   \n",
       "22                               In Eqn. ^^^^^^^(b) ^   \n",
       "23   The model accurately reproduces tlie twin lob...   \n",
       "24   It is possible, furthermore, that some of the...   \n",
       "25   When the mass of such a shell reaches some cr...   \n",
       "26  . It should also be noted that most of the upp...   \n",
       "27  . There are also indications in nearby regious...   \n",
       "28   Two of the remai^une three ^5a^S (adl617. 1d1...   \n",
       "29  07. consistent with the predicted nature of he...   \n",
       "30   Onlv iu about ^^^^^^^data. acllition or subtr...   \n",
       "31   We start a driven turbulence simulation witho...   \n",
       "32   Despite considerable uncertainties 1n. the mo...   \n",
       "33   Plots of ^(^^f,^^^.f5.f.)^ ave shown in figur...   \n",
       "34   In Figure l. we have shown a sample backgroun...   \n",
       "35  . The properties of the objects that are relev...   \n",
       "36   Initially the variation in the accretion rate...   \n",
       "37   We have then computed the median and confiden...   \n",
       "38   This may be a result of accitional shocks and...   \n",
       "39                                            In Fig.   \n",
       "\n",
       "                             aligned sentences target  \\\n",
       "20        This might reduce the rms scatter slightly.   \n",
       "21   We are grateful to Butler Burton, Carl @Heile...   \n",
       "22                               In Eqn. \\ref{SDE}) )   \n",
       "23   The model accurately reproduces th@e twin lob...   \n",
       "24   It is possible, furthermore, that some of the...   \n",
       "25   When the mass of such a shell reaches some cr...   \n",
       "26  @ It should also be noted that most of the upp...   \n",
       "27  @ There are also indications in nearby regions...   \n",
       "28   Two of the remaining three stars (id1647, id1...   \n",
       "29  @@@ consistent with the predicted nature of he...   \n",
       "30   Only in about of the data, add@ition or subtr...   \n",
       "31   We start a driven turbulence simulation witho...   \n",
       "32   Despite considerable uncertainties in@ the mo...   \n",
       "33   Plots of $(t_a, t_b, t_c)$ are shown in figur...   \n",
       "34   In Figure 1, we have shown a sample backgroun...   \n",
       "35  @ The properties of the objects that are relev...   \n",
       "36   Initially the variation in the accretion rate...   \n",
       "37   We have then computed the median and confiden...   \n",
       "38   This may be a result of additional shocks and...   \n",
       "39                                            In Fig.   \n",
       "\n",
       "                                     sentences source  \\\n",
       "20        This might reduce the rms scatter slightly.   \n",
       "21   We are grateful to Butler Burton. Carl IHeile...   \n",
       "22                                       In Eqn. (b)    \n",
       "23   The model accurately reproduces tlie twin lob...   \n",
       "24   It is possible, furthermore, that some of the...   \n",
       "25   When the mass of such a shell reaches some cr...   \n",
       "26  . It should also be noted that most of the upp...   \n",
       "27  . There are also indications in nearby regious...   \n",
       "28   Two of the remaiune three 5aS (adl617. 1d1659...   \n",
       "29  07. consistent with the predicted nature of he...   \n",
       "30   Onlv iu about data. acllition or subtraction ...   \n",
       "31   We start a driven turbulence simulation witho...   \n",
       "32   Despite considerable uncertainties 1n. the mo...   \n",
       "33        Plots of (f,.f5.f.) ave shown in figure 5..   \n",
       "34   In Figure l. we have shown a sample backgroun...   \n",
       "35  . The properties of the objects that are relev...   \n",
       "36   Initially the variation in the accretion rate...   \n",
       "37   We have then computed the median and confiden...   \n",
       "38   This may be a result of accitional shocks and...   \n",
       "39                                            In Fig.   \n",
       "\n",
       "                                     sentences target  \\\n",
       "20        This might reduce the rms scatter slightly.   \n",
       "21   We are grateful to Butler Burton, Carl Heiles...   \n",
       "22                               In Eqn. \\ref{SDE}) )   \n",
       "23   The model accurately reproduces the twin lobe...   \n",
       "24   It is possible, furthermore, that some of the...   \n",
       "25   When the mass of such a shell reaches some cr...   \n",
       "26   It should also be noted that most of the uppe...   \n",
       "27   There are also indications in nearby regions ...   \n",
       "28   Two of the remaining three stars (id1647, id1...   \n",
       "29   consistent with the predicted nature of heliu...   \n",
       "30   Only in about of the data, addition or subtra...   \n",
       "31   We start a driven turbulence simulation witho...   \n",
       "32   Despite considerable uncertainties in the mod...   \n",
       "33   Plots of $(t_a, t_b, t_c)$ are shown in figur...   \n",
       "34   In Figure 1, we have shown a sample backgroun...   \n",
       "35   The properties of the objects that are releva...   \n",
       "36   Initially the variation in the accretion rate...   \n",
       "37   We have then computed the median and confiden...   \n",
       "38   This may be a result of additional shocks and...   \n",
       "39                                            In Fig.   \n",
       "\n",
       "                       aligned sentences source types  \\\n",
       "20        WWWW WWWWW WWWWWW WWW WWW WWWWWWW WWWWWWWWW   \n",
       "21   WW WWW WWWWWWWW WW WWWWWW WWWWWWW WWWW WWWWWW...   \n",
       "22                               WW WWWW ^^^^^^^WWW ^   \n",
       "23   WWW WWWWW WWWWWWWWWW WWWWWWWWWW WWWW WWWW WWW...   \n",
       "24   WW WW WWWWWWWWW WWWWWWWWWWWW WWWW WWWW WW WWW...   \n",
       "25   WWWW WWW WWWW WW WWWW W WWWWW WWWWWWW WWWW WW...   \n",
       "26  W WW WWWWWW WWWW WW WWWWW WWWW WWWW WW WWW WWW...   \n",
       "27  W WWWWW WWW WWWW WWWWWWWWWWW WW WWWWWW WWWWWWW...   \n",
       "28   WWW WW WWW WWWWW^WWW WWWWW ^WW^W WWWWWWWW WWW...   \n",
       "29  WWW WWWWWWWWWW WWWW WWW WWWWWWWWW WWWWWW WW WW...   \n",
       "30   WWWW WW WWWWW ^^^^^^^WWWWW WWWWWWWWW WW WWWWW...   \n",
       "31   WW WWWWW W WWWWWW WWWWWWWWWW WWWWWWWWWW WWWWW...   \n",
       "32   WWWWWWW WWWWWWWWWWWW WWWWWWWWWWWWW WWW WWW WW...   \n",
       "33   WWWWW WW ^I^^II^^^IIIIIII^ WWW WWWWW WW WWWWW...   \n",
       "34   WW WWWWWW WW WW WWWW WWWWW W WWWWWW WWWWWWWWW...   \n",
       "35  W WWW WWWWWWWWWW WW WWW WWWWWWW WWWW WWW WWWWW...   \n",
       "36   WWWWWWWWW WWW WWWWWWWWW WW WWW WWWWWWWWW WWWW...   \n",
       "37   WW WWWW WWWW WWWWWWWW WWW WWWWWW WWW WWWWWWWW...   \n",
       "38   WWWW WWW WW W WWWWWW WW WWWWWWWWWW WWWWWW WWW...   \n",
       "39                                            WW WWWW   \n",
       "\n",
       "                       aligned sentences target types  \\\n",
       "20        WWWW WWWWW WWWWWW WWW WWW WWWWWWW WWWWWWWWW   \n",
       "21   WW WWW WWWWWWWW WW WWWWWW WWWWWWW WWWW @WWWWW...   \n",
       "22                               WW WWWW RRRRRRRRRW W   \n",
       "23   WWW WWWWW WWWWWWWWWW WWWWWWWWWW WW@W WWWW WWW...   \n",
       "24   WW WW WWWWWWWWW WWWWWWWWWWWW WWWW WWWW WW WWW...   \n",
       "25   WWWW WWW WWWW WW WWWW W WWWWW WWWWWWW WWWW WW...   \n",
       "26  @ WW WWWWWW WWWW WW WWWWW WWWW WWWW WW WWW WWW...   \n",
       "27  @ WWWWW WWW WWWW WWWWWWWWWWW WW WWWWWW WWWWWWW...   \n",
       "28   WWW WW WWW WWWWWWWWW WWWWW WWWWW WWWWWWWW WWW...   \n",
       "29  @@@ WWWWWWWWWW WWWW WWW WWWWWWWWW WWWWWW WW WW...   \n",
       "30   WWWW WW WWWWW WW WWW WWWWW WWW@WWWWW WW WWWWW...   \n",
       "31   WW WWWWW W WWWWWW WWWWWWWWWW WWWWWWWWWW WWWWW...   \n",
       "32   WWWWWWW WWWWWWWWWWWW WWWWWWWWWWWWW WW@ WWW WW...   \n",
       "33   WWWWW WW IIIIIIIIIIIIIIIII WWW WWWWW WW WWWWW...   \n",
       "34   WW WWWWWW WW WW WWWW WWWWW W WWWWWW WWWWWWWWW...   \n",
       "35  @ WWW WWWWWWWWWW WW WWW WWWWWWW WWWW WWW WWWWW...   \n",
       "36   WWWWWWWWW WWW WWWWWWWWW WW WWW WWWWWWWWW WWWW...   \n",
       "37   WW WWWW WWWW WWWWWWWW WWW WWWWWW WWW WWWWWWWW...   \n",
       "38   WWWW WWW WW W WWWWWW WW WWWWWWWWWW WWWWWW WWW...   \n",
       "39                                            WW WWWW   \n",
       "\n",
       "                               sentences source types  \\\n",
       "20        WWWW WWWWW WWWWWW WWW WWW WWWWWWW WWWWWWWWW   \n",
       "21   WW WWW WWWWWWWW WW WWWWWW WWWWWWW WWWW WWWWWW...   \n",
       "22                                       WW WWWW WWW    \n",
       "23   WWW WWWWW WWWWWWWWWW WWWWWWWWWW WWWW WWWW WWW...   \n",
       "24   WW WW WWWWWWWWW WWWWWWWWWWWW WWWW WWWW WW WWW...   \n",
       "25   WWWW WWW WWWW WW WWWW W WWWWW WWWWWWW WWWW WW...   \n",
       "26  W WW WWWWWW WWWW WW WWWWW WWWW WWWW WW WWW WWW...   \n",
       "27  W WWWWW WWW WWWW WWWWWWWWWWW WW WWWWWW WWWWWWW...   \n",
       "28   WWW WW WWW WWWWWWWW WWWWW WWW WWWWWWWW WWWWWW...   \n",
       "29  WWW WWWWWWWWWW WWWW WWW WWWWWWWWW WWWWWW WW WW...   \n",
       "30   WWWW WW WWWWW WWWWW WWWWWWWWW WW WWWWWWWWWWW ...   \n",
       "31   WW WWWWW W WWWWWW WWWWWWWWWW WWWWWWWWWW WWWWW...   \n",
       "32   WWWWWWW WWWWWWWWWWWW WWWWWWWWWWWWW WWW WWW WW...   \n",
       "33        WWWWW WW IIIIIIIIII WWW WWWWW WW WWWWWW RRW   \n",
       "34   WW WWWWWW WW WW WWWW WWWWW W WWWWWW WWWWWWWWW...   \n",
       "35  W WWW WWWWWWWWWW WW WWW WWWWWWW WWWW WWW WWWWW...   \n",
       "36   WWWWWWWWW WWW WWWWWWWWW WW WWW WWWWWWWWW WWWW...   \n",
       "37   WW WWWW WWWW WWWWWWWW WWW WWWWWW WWW WWWWWWWW...   \n",
       "38   WWWW WWW WW W WWWWWW WW WWWWWWWWWW WWWWWW WWW...   \n",
       "39                                            WW WWWW   \n",
       "\n",
       "                               sentences target types  \\\n",
       "20        WWWW WWWWW WWWWWW WWW WWW WWWWWWW WWWWWWWWW   \n",
       "21   WW WWW WWWWWWWW WW WWWWWW WWWWWWW WWWW WWWWWW...   \n",
       "22                               WW WWWW RRRRRRRRRW W   \n",
       "23   WWW WWWWW WWWWWWWWWW WWWWWWWWWW WWW WWWW WWWW...   \n",
       "24   WW WW WWWWWWWWW WWWWWWWWWWWW WWWW WWWW WW WWW...   \n",
       "25   WWWW WWW WWWW WW WWWW W WWWWW WWWWWWW WWWW WW...   \n",
       "26   WW WWWWWW WWWW WW WWWWW WWWW WWWW WW WWW WWWW...   \n",
       "27   WWWWW WWW WWWW WWWWWWWWWWW WW WWWWWW WWWWWWW ...   \n",
       "28   WWW WW WWW WWWWWWWWW WWWWW WWWWW WWWWWWWW WWW...   \n",
       "29   WWWWWWWWWW WWWW WWW WWWWWWWWW WWWWWW WW WWWWW...   \n",
       "30   WWWW WW WWWWW WW WWW WWWWW WWWWWWWW WW WWWWWW...   \n",
       "31   WW WWWWW W WWWWWW WWWWWWWWWW WWWWWWWWWW WWWWW...   \n",
       "32   WWWWWWW WWWWWWWWWWWW WWWWWWWWWWWWW WW WWW WWW...   \n",
       "33   WWWWW WW IIIIIIIIIIIIIIIII WWW WWWWW WW WWWWW...   \n",
       "34   WW WWWWWW WW WW WWWW WWWWW W WWWWWW WWWWWWWWW...   \n",
       "35   WWW WWWWWWWWWW WW WWW WWWWWWW WWWW WWW WWWWWW...   \n",
       "36   WWWWWWWWW WWW WWWWWWWWW WW WWW WWWWWWWWW WWWW...   \n",
       "37   WW WWWW WWWW WWWWWWWW WWW WWWWWW WWW WWWWWWWW...   \n",
       "38   WWWW WWW WW W WWWWWW WW WWWWWWWWWW WWWWWW WWW...   \n",
       "39                                            WW WWWW   \n",
       "\n",
       "                                       predicted_text  \n",
       "20        This might reduce the rms scatter slightly.  \n",
       "21   We are grateful to Butler Burton, Carl Heiles...  \n",
       "22                                               None  \n",
       "23                                               None  \n",
       "24                                               None  \n",
       "25                                               None  \n",
       "26                                               None  \n",
       "27                                               None  \n",
       "28                                               None  \n",
       "29                                               None  \n",
       "30                                               None  \n",
       "31                                               None  \n",
       "32                                               None  \n",
       "33                                               None  \n",
       "34                                               None  \n",
       "35                                               None  \n",
       "36                                               None  \n",
       "37                                               None  \n",
       "38                                               None  \n",
       "39                                               None  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd4a531-d009-41db-8c0b-78b5e6eef1ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "1. after debudding for one sentence -->try to doing for 10~500?? sentences --> save the output in a df then csv\n",
    "2. 10 sentences --> how well -->printout the source setnence and output sentence --> how it is doing.. train long less gobble\n",
    "3. quantify accuracy -->edit distance ,, pop algorithm --> we will use the libraries but it is helpful to understand (description)\n",
    "4. calculate edited distance! example on the doc --> high distance == farther --> wanna minimize it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052188b6-3e40-4a18-9990-602a661ccc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d4273-960a-4690-8220-650e4612a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eecb9cc-df3d-434a-a68d-6ee81b319bfb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Edit Distance --> make sure to do the full dfataset -->remove Nan from calculation and count the nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b92d7bee-7797-404e-ba01-885540521dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a0ab82b-8f15-434c-80a6-27c4466fe181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(\"lewenstein\", \"levenshtein\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0466c452-9291-44e3-9cf8-ff945f48bdf8",
   "metadata": {},
   "source": [
    "#### Initial error: Edit distance of âsentences sourceâ vs âsentences targetâ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465a35bf-211c-42da-9808-408024afc28d",
   "metadata": {},
   "source": [
    "<!-- ##### df10 = pd.read_csv(output_dir + \"s10_small_words.csv\") -->\n",
    "df10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "119b6bee-b46f-450e-8fb5-443a87d57725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "12\n",
      "4\n",
      "3\n",
      "16\n",
      "19\n",
      "12\n",
      "9\n",
      "17\n",
      "22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[33, 12, 4, 3, 16, 19, 12, 9, 17, 22]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_dis = []\n",
    "for i in range(df10.shape[0]):\n",
    "    print(distance(df10[\"sentences source\"][i], df10[\"sentences target\"][i]))\n",
    "    initial_dis.append(distance(df10[\"sentences source\"][i], df10[\"sentences target\"][i]))\n",
    "initial_dis    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "687c7a32-0f11-4ad8-9d7f-ee36df9ca832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(initial_dis)/10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb62f7a-cc99-408e-9d9d-bd9f9ef26d00",
   "metadata": {},
   "source": [
    "#### Post-corrected error: Edit distance of âoutput_textâ from model vs âsentences targetâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5f59682-48aa-4347-be82-ec4b74d55dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n",
      "7\n",
      "0\n",
      "12\n",
      "11\n",
      "6\n",
      "6\n",
      "4\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9, 9, 7, 0, 12, 11, 6, 6, 4, 10]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_error = []\n",
    "for i in range(df10.shape[0]):\n",
    "    print(distance(df10[\"predicted_text\"][i], df10[\"sentences target\"][i]))\n",
    "    post_error.append(distance(df10[\"predicted_text\"][i], df10[\"sentences target\"][i]))\n",
    "post_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90df3807-e2af-4ffd-9c3e-c8d6436a16f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(post_error)/10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84139e3c-d301-4cde-b2da-190841a07a85",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### For 20 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36e60575-d334-4142-91eb-07e681fcaf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aligned sentences source</th>\n",
       "      <th>aligned sentences target</th>\n",
       "      <th>sentences source</th>\n",
       "      <th>sentences target</th>\n",
       "      <th>aligned sentences source types</th>\n",
       "      <th>aligned sentences target types</th>\n",
       "      <th>sentences source types</th>\n",
       "      <th>sentences target types</th>\n",
       "      <th>predicted_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A histogram of the ^^^^^^^Va^^^ /slope for dw...</td>\n",
       "      <td>A histogram of the $_{\\rm max}$ /slope for dw...</td>\n",
       "      <td>A histogram of the Va /slope for dwarf irregu...</td>\n",
       "      <td>A histogram of the $_{\\rm max}$ /slope for dw...</td>\n",
       "      <td>W WWWWWWWWW WW WWW ^^^^^^^II^^^ WWWWWW WWW WW...</td>\n",
       "      <td>W WWWWWWWWW WW WWW IIIIIIIIIIII WWWWWW WWW WW...</td>\n",
       "      <td>W WWWWWWWWW WW WWW II WWWWWW WWW WWWWW WWWWWW...</td>\n",
       "      <td>W WWWWWWWWW WW WWW IIIIIIIIIIII WWWWWW WWW WW...</td>\n",
       "      <td>A histogram of the $\\alpha$ /slope for dwarf ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Observations were carried out. using ^^a log ...</td>\n",
       "      <td>Observations were carried out@ using â a log ...</td>\n",
       "      <td>Observations were carried out. using a log of...</td>\n",
       "      <td>Observations were carried out using â a log o...</td>\n",
       "      <td>WWWWWWWWWWWW WWWW WWWWWWW WWWW WWWWW ^^W WWW ...</td>\n",
       "      <td>WWWWWWWWWWWW WWWW WWWWWWW WWW@ WWWWW W W WWW ...</td>\n",
       "      <td>WWWWWWWWWWWW WWWW WWWWWWW WWWW WWWWW W WWW WW...</td>\n",
       "      <td>WWWWWWWWWWWW WWWW WWWWWWW WWW WWWWW W W WWW W...</td>\n",
       "      <td>Observations were carried out, using a log of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compared to a smooth polynomial. the flat fie...</td>\n",
       "      <td>Compared to a smooth polynomial, the flat fie...</td>\n",
       "      <td>Compared to a smooth polynomial. the flat fie...</td>\n",
       "      <td>Compared to a smooth polynomial, the flat fie...</td>\n",
       "      <td>WWWWWWWW WW W WWWWWW WWWWWWWWWWW WWW WWWW WWW...</td>\n",
       "      <td>WWWWWWWW WW W WWWWWW WWWWWWWWWWW WWW WWWW WWW...</td>\n",
       "      <td>WWWWWWWW WW W WWWWWW WWWWWWWWWWW WWW WWWW WWW...</td>\n",
       "      <td>WWWWWWWW WW W WWWWWW WWWWWWWWWWW WWW WWWW WWW...</td>\n",
       "      <td>Compared to a smooth polynomial, the flat fie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006) confirmed. lis scenario.</td>\n",
       "      <td>2006) confirmed this scenario.</td>\n",
       "      <td>2006) confirmed. lis scenario.</td>\n",
       "      <td>2006) confirmed this scenario.</td>\n",
       "      <td>WWWWW WWWWWWWWWW WWW WWWWWWWWW</td>\n",
       "      <td>WWWWW WWWWWWWWW WWWW WWWWWWWWW</td>\n",
       "      <td>WWWWW WWWWWWWWWW WWW WWWWWWWWW</td>\n",
       "      <td>WWWWW WWWWWWWWW WWWW WWWWWWWWW</td>\n",
       "      <td>2006) confirmed this scenario.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thus. slieht differences in ihe ^^^Â©C'a ^^^^v...</td>\n",
       "      <td>Thus, slight differences in the $\\Sigma Ca$ v...</td>\n",
       "      <td>Thus. slieht differences in ihe Â©C'a value of...</td>\n",
       "      <td>Thus, slight differences in the $\\Sigma Ca$ v...</td>\n",
       "      <td>WWWWW WWWWWW WWWWWWWWWWW WW WWW ^^^IIIII^^^^W...</td>\n",
       "      <td>WWWWW WWWWWW WWWWWWWWWWW WW WWW IIIIIIIIIII W...</td>\n",
       "      <td>WWWWW WWWWWW WWWWWWWWWWW WW WWW IIIIIWWWWW WW...</td>\n",
       "      <td>WWWWW WWWWWW WWWWWWWWWWW WW WWW IIIIIIIIIII W...</td>\n",
       "      <td>Thus, slight differences in the $\\Omega$ Ca v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            aligned sentences source  \\\n",
       "0   A histogram of the ^^^^^^^Va^^^ /slope for dw...   \n",
       "1   Observations were carried out. using ^^a log ...   \n",
       "2   Compared to a smooth polynomial. the flat fie...   \n",
       "3                     2006) confirmed. lis scenario.   \n",
       "4   Thus. slieht differences in ihe ^^^Â©C'a ^^^^v...   \n",
       "\n",
       "                            aligned sentences target  \\\n",
       "0   A histogram of the $_{\\rm max}$ /slope for dw...   \n",
       "1   Observations were carried out@ using â a log ...   \n",
       "2   Compared to a smooth polynomial, the flat fie...   \n",
       "3                     2006) confirmed this scenario.   \n",
       "4   Thus, slight differences in the $\\Sigma Ca$ v...   \n",
       "\n",
       "                                    sentences source  \\\n",
       "0   A histogram of the Va /slope for dwarf irregu...   \n",
       "1   Observations were carried out. using a log of...   \n",
       "2   Compared to a smooth polynomial. the flat fie...   \n",
       "3                     2006) confirmed. lis scenario.   \n",
       "4   Thus. slieht differences in ihe Â©C'a value of...   \n",
       "\n",
       "                                    sentences target  \\\n",
       "0   A histogram of the $_{\\rm max}$ /slope for dw...   \n",
       "1   Observations were carried out using â a log o...   \n",
       "2   Compared to a smooth polynomial, the flat fie...   \n",
       "3                     2006) confirmed this scenario.   \n",
       "4   Thus, slight differences in the $\\Sigma Ca$ v...   \n",
       "\n",
       "                      aligned sentences source types  \\\n",
       "0   W WWWWWWWWW WW WWW ^^^^^^^II^^^ WWWWWW WWW WW...   \n",
       "1   WWWWWWWWWWWW WWWW WWWWWWW WWWW WWWWW ^^W WWW ...   \n",
       "2   WWWWWWWW WW W WWWWWW WWWWWWWWWWW WWW WWWW WWW...   \n",
       "3                     WWWWW WWWWWWWWWW WWW WWWWWWWWW   \n",
       "4   WWWWW WWWWWW WWWWWWWWWWW WW WWW ^^^IIIII^^^^W...   \n",
       "\n",
       "                      aligned sentences target types  \\\n",
       "0   W WWWWWWWWW WW WWW IIIIIIIIIIII WWWWWW WWW WW...   \n",
       "1   WWWWWWWWWWWW WWWW WWWWWWW WWW@ WWWWW W W WWW ...   \n",
       "2   WWWWWWWW WW W WWWWWW WWWWWWWWWWW WWW WWWW WWW...   \n",
       "3                     WWWWW WWWWWWWWW WWWW WWWWWWWWW   \n",
       "4   WWWWW WWWWWW WWWWWWWWWWW WW WWW IIIIIIIIIII W...   \n",
       "\n",
       "                              sentences source types  \\\n",
       "0   W WWWWWWWWW WW WWW II WWWWWW WWW WWWWW WWWWWW...   \n",
       "1   WWWWWWWWWWWW WWWW WWWWWWW WWWW WWWWW W WWW WW...   \n",
       "2   WWWWWWWW WW W WWWWWW WWWWWWWWWWW WWW WWWW WWW...   \n",
       "3                     WWWWW WWWWWWWWWW WWW WWWWWWWWW   \n",
       "4   WWWWW WWWWWW WWWWWWWWWWW WW WWW IIIIIWWWWW WW...   \n",
       "\n",
       "                              sentences target types  \\\n",
       "0   W WWWWWWWWW WW WWW IIIIIIIIIIII WWWWWW WWW WW...   \n",
       "1   WWWWWWWWWWWW WWWW WWWWWWW WWW WWWWW W W WWW W...   \n",
       "2   WWWWWWWW WW W WWWWWW WWWWWWWWWWW WWW WWWW WWW...   \n",
       "3                     WWWWW WWWWWWWWW WWWW WWWWWWWWW   \n",
       "4   WWWWW WWWWWW WWWWWWWWWWW WW WWW IIIIIIIIIII W...   \n",
       "\n",
       "                                      predicted_text  \n",
       "0   A histogram of the $\\alpha$ /slope for dwarf ...  \n",
       "1   Observations were carried out, using a log of...  \n",
       "2   Compared to a smooth polynomial, the flat fie...  \n",
       "3                     2006) confirmed this scenario.  \n",
       "4   Thus, slight differences in the $\\Omega$ Ca v...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df20 = pd.read_csv(output_dir + \"s10_small_words.csv\")\n",
    "df20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da9995dd-96be-48a7-95ec-37661d4d3a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "12\n",
      "4\n",
      "3\n",
      "16\n",
      "19\n",
      "12\n",
      "9\n",
      "17\n",
      "22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[33, 12, 4, 3, 16, 19, 12, 9, 17, 22]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initial error\n",
    "initial_dis20 = []\n",
    "for i in range(df10.shape[0]):\n",
    "    print(distance(df10[\"sentences source\"][i], df10[\"sentences target\"][i]))\n",
    "    initial_dis20.append(distance(df10[\"sentences source\"][i], df10[\"sentences target\"][i]))\n",
    "initial_dis20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5226b506-2eb4-4f86-b4e3-68246e50218c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.35"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(initial_dis20)/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f91c17b-0bac-4232-afe5-6305bbb717db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n",
      "7\n",
      "0\n",
      "12\n",
      "11\n",
      "6\n",
      "6\n",
      "4\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9, 9, 7, 0, 12, 11, 6, 6, 4, 10]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_error20 = []\n",
    "for i in range(df10.shape[0]):\n",
    "    print(distance(df10[\"predicted_text\"][i], df10[\"sentences target\"][i]))\n",
    "    post_error20.append(distance(df10[\"predicted_text\"][i], df10[\"sentences target\"][i]))\n",
    "post_error20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c2f827d-1ca4-450b-94dd-5d9b46418842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(post_error20)/20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba94cf81-5ee0-4222-8bb3-2352ee1f9a62",
   "metadata": {
    "tags": []
   },
   "source": [
    "## yelpfeast/byt5-base-english-ocr-correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40789b85-0a4a-4ef5-b601-414d68bab86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        A histogram of the Va /slope for dwarf irregu...\n",
       "1        Observations were carried out. using a log of...\n",
       "2        Compared to a smooth polynomial. the flat fie...\n",
       "3                          2006) confirmed. lis scenario.\n",
       "4        Thus. slieht differences in ihe Â©C'a value of...\n",
       "                              ...                        \n",
       "9995     TIe X-ray spectra obtaiied with previous low-...\n",
       "9996     This variation stems primarily from the initi...\n",
       "9997     Leroyetal.(2008) aud Dieielet used the 21 fux...\n",
       "9998     Making use of the approximation that p=X/H gi...\n",
       "9999           This is qualitatively consistent (see Fig.\n",
       "Name: sentences source, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = np.arange(0,len(test_df))\n",
    "text = test_df.iloc[inds][\"sentences source\"]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f45e50d-14b8-41dd-8b6d-e933783a2fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511 : error or timeout in model\n"
     ]
    }
   ],
   "source": [
    "df2 = test_df.iloc[inds].copy()\n",
    "df2['predicted_text'] = None\n",
    "\n",
    "for i in range(text.shape[0]):\n",
    "    if i%100 == 0:\n",
    "        filename = output_dir_ + 's' + str(i) + ender + '.csv' \n",
    "        df2.to_csv(filename, index=False)\n",
    "    try: \n",
    "        with timeout(seconds=int(wait_timeout)):\n",
    "            inputs = tokenizer(text[i], padding=\"longest\", return_tensors=\"pt\")\n",
    "            output = model.generate(**inputs)\n",
    "            output_text = tokenizer.decode(output[0], \n",
    "                                            skip_special_tokens=skip_specials, \n",
    "                                            clean_up_tokenization_spaces=True)\n",
    "            output_text = str(output_text)\n",
    "    except:\n",
    "        #import sys; sys.exit()\n",
    "        print(i, ': error or timeout in model')\n",
    "        output_text = np.nan\n",
    "        err = True\n",
    "    df2['predicted_text'][i] = output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbcb6da-b28e-4e52-a856-5248c95ce90e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## yelpfeast/byt5-base-english-ocr-correction (not fully trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d45693-b1f7-4768-96ba-907e8f51ecf8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f579ffe5-ae5b-4989-9e16-9a11311e73cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' A histogram of the $V_{\\\\rm d}$ /slope for dwarf irregular galaxies is shown in Figure \\\\ref{fig:slope}b b, where the slope of the rotation curve is in units of per scale length.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = 0\n",
    "text = test_df.iloc[inds][\"sentences source\"]\n",
    "\n",
    "with timeout(seconds=int(wait_timeout)):\n",
    "    inputs = tokenizer(text, padding=\"longest\", return_tensors=\"pt\")\n",
    "    output = model.generate(**inputs)\n",
    "    output_text = tokenizer.decode(output[0], \n",
    "                                    skip_special_tokens=skip_specials, \n",
    "                                    clean_up_tokenization_spaces=True)\n",
    "    output_text = str(output_text)\n",
    "\n",
    "output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd3c9e-d317-45c7-9bff-393d687bd0de",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 10 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88de0100-eefb-4a30-b3f8-6bd1ffb8b4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     A histogram of the Va /slope for dwarf irregu...\n",
       "1     Observations were carried out. using a log of...\n",
       "2     Compared to a smooth polynomial. the flat fie...\n",
       "3                       2006) confirmed. lis scenario.\n",
       "4     Thus. slieht differences in ihe Â©C'a value of...\n",
       "5     We can derive similar constraints on Q,, gene...\n",
       "6     As anticipated. we find no unstable p-miocdes...\n",
       "7     In thisLetter. I discuss an effectthatusespre...\n",
       "8     As a result of many vears of work onu the nat...\n",
       "9     Taken as a whole. Figure 5. is evidence for a...\n",
       "Name: sentences source, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = np.arange(0,10)\n",
    "text = test_df.iloc[inds][\"sentences source\"]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18833c53-a075-4ed0-84b8-c2e40f886e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = test_df.iloc[inds].copy()\n",
    "df2['predicted_text'] = None\n",
    "\n",
    "for i in range(text.shape[0]):\n",
    "    with timeout(seconds=int(wait_timeout)):\n",
    "        inputs = tokenizer(text[i], padding=\"longest\", return_tensors=\"pt\")\n",
    "        output = model.generate(**inputs)\n",
    "        output_text = tokenizer.decode(output[0], \n",
    "                                        skip_special_tokens=skip_specials, \n",
    "                                        clean_up_tokenization_spaces=True)\n",
    "        output_text = str(output_text)\n",
    "        df2['predicted_text'][i] = output_text\n",
    "# output_dir --> output_dir_ cuz conlficts with the snapshot     \n",
    "\n",
    "filename = output_dir_ + 's' + str(len(inds)) + ender + '.csv' \n",
    "df2.to_csv(filename, index=False)\n",
    "del df2\n",
    "del output_text\n",
    "del text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617c562f-fc3d-451f-96f2-56aaaaef2d8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 20 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0595272b-3703-410e-afc7-4e476e50c589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      A histogram of the Va /slope for dwarf irregu...\n",
       "1      Observations were carried out. using a log of...\n",
       "2      Compared to a smooth polynomial. the flat fie...\n",
       "3                        2006) confirmed. lis scenario.\n",
       "4      Thus. slieht differences in ihe Â©C'a value of...\n",
       "5      We can derive similar constraints on Q,, gene...\n",
       "6      As anticipated. we find no unstable p-miocdes...\n",
       "7      In thisLetter. I discuss an effectthatusespre...\n",
       "8      As a result of many vears of work onu the nat...\n",
       "9      Taken as a whole. Figure 5. is evidence for a...\n",
       "10     ust be ultiplied by the factor 2222 which is ...\n",
       "11     We experimented with including different. Aer...\n",
       "12     In particular. it has been known for many yea...\n",
       "13     The amplitucle of the power spectrui is a non...\n",
       "14     This contrasts with the behaviour of the MesÂ»...\n",
       "15                   This eave 5976 PAIN radio sources.\n",
       "16     However. it is imperative to include in (he g...\n",
       "17     For these simulations. softening lengths at b...\n",
       "18     The surface brightness. (8) is given by the i...\n",
       "19     Dased on the BATC survey observations. (he ma...\n",
       "Name: sentences source, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = np.arange(0,20)\n",
    "text = test_df.iloc[inds][\"sentences source\"]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5e6b8f7-f2a9-4a5c-b23c-4a3eab97b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = test_df.iloc[inds].copy()\n",
    "df2['predicted_text'] = None\n",
    "\n",
    "for i in range(text.shape[0]):\n",
    "    with timeout(seconds=int(wait_timeout)):\n",
    "        inputs = tokenizer(text[i], padding=\"longest\", return_tensors=\"pt\")\n",
    "        output = model.generate(**inputs)\n",
    "        output_text = tokenizer.decode(output[0], \n",
    "                                        skip_special_tokens=skip_specials, \n",
    "                                        clean_up_tokenization_spaces=True)\n",
    "        output_text = str(output_text)\n",
    "        df2['predicted_text'][i] = output_text\n",
    "# output_dir --> output_dir_ cuz conlficts with the snapshot     \n",
    "\n",
    "filename = output_dir_ + 's' + str(len(inds)) + ender + '.csv' \n",
    "df2.to_csv(filename, index=False)\n",
    "del df2\n",
    "del output_text\n",
    "del text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968d0ca7-8831-4940-ae40-88ebbbf074d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 50 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5437dcf-0ae8-44bb-b285-54ef53c51632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      A histogram of the Va /slope for dwarf irregu...\n",
       "1      Observations were carried out. using a log of...\n",
       "2      Compared to a smooth polynomial. the flat fie...\n",
       "3                        2006) confirmed. lis scenario.\n",
       "4      Thus. slieht differences in ihe Â©C'a value of...\n",
       "5      We can derive similar constraints on Q,, gene...\n",
       "6      As anticipated. we find no unstable p-miocdes...\n",
       "7      In thisLetter. I discuss an effectthatusespre...\n",
       "8      As a result of many vears of work onu the nat...\n",
       "9      Taken as a whole. Figure 5. is evidence for a...\n",
       "10     ust be ultiplied by the factor 2222 which is ...\n",
       "11     We experimented with including different. Aer...\n",
       "12     In particular. it has been known for many yea...\n",
       "13     The amplitucle of the power spectrui is a non...\n",
       "14     This contrasts with the behaviour of the MesÂ»...\n",
       "15                   This eave 5976 PAIN radio sources.\n",
       "16     However. it is imperative to include in (he g...\n",
       "17     For these simulations. softening lengths at b...\n",
       "18     The surface brightness. (8) is given by the i...\n",
       "19     Dased on the BATC survey observations. (he ma...\n",
       "20          This might reduce the rms scatter slightly.\n",
       "21     We are grateful to Butler Burton. Carl IHeile...\n",
       "22                                         In Eqn. (b) \n",
       "23     The model accurately reproduces tlie twin lob...\n",
       "24     It is possible, furthermore, that some of the...\n",
       "25     When the mass of such a shell reaches some cr...\n",
       "26    . It should also be noted that most of the upp...\n",
       "27    . There are also indications in nearby regious...\n",
       "28     Two of the remaiune three 5aS (adl617. 1d1659...\n",
       "29    07. consistent with the predicted nature of he...\n",
       "30     Onlv iu about data. acllition or subtraction ...\n",
       "31     We start a driven turbulence simulation witho...\n",
       "32     Despite considerable uncertainties 1n. the mo...\n",
       "33          Plots of (f,.f5.f.) ave shown in figure 5..\n",
       "34     In Figure l. we have shown a sample backgroun...\n",
       "35    . The properties of the objects that are relev...\n",
       "36     Initially the variation in the accretion rate...\n",
       "37     We have then computed the median and confiden...\n",
       "38     This may be a result of accitional shocks and...\n",
       "39                                              In Fig.\n",
       "40    . Current theory proposes a top-leavy initial ...\n",
       "41     Neighboring lines in the model are both too s...\n",
       "42    b) we present the moment-equation results lor ...\n",
       "43        Atmospheric nons ave recorded at arate of Wz.\n",
       "44     The Parkes survey Was subsequentIv expanded t...\n",
       "45     Small-scale structures evolve to larger scale...\n",
       "46     This is highly encouraging for numerical simu...\n",
       "47     The lack of a correlation between f aud leus ...\n",
       "48     It should benoted that for models with Hpz# 0...\n",
       "49     There are reasons to question whether the dis...\n",
       "Name: sentences source, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = np.arange(0,50)\n",
    "text = test_df.iloc[inds][\"sentences source\"]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af27d786-ad82-461d-b829-194caa01fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = test_df.iloc[inds].copy()\n",
    "df2['predicted_text'] = None\n",
    "\n",
    "for i in range(text.shape[0]):\n",
    "    with timeout(seconds=int(wait_timeout)):\n",
    "        inputs = tokenizer(text[i], padding=\"longest\", return_tensors=\"pt\")\n",
    "        output = model.generate(**inputs)\n",
    "        output_text = tokenizer.decode(output[0], \n",
    "                                        skip_special_tokens=skip_specials, \n",
    "                                        clean_up_tokenization_spaces=True)\n",
    "        output_text = str(output_text)\n",
    "        df2['predicted_text'][i] = output_text\n",
    "# output_dir --> output_dir_ cuz conlficts with the snapshot     \n",
    "\n",
    "filename = output_dir_ + 's' + str(len(inds)) + ender + '.csv' \n",
    "df2.to_csv(filename, index=False)\n",
    "del df2\n",
    "del output_text\n",
    "del text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997e52b9-01a2-44e7-8fb6-714fe8b0be84",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ea572df-bd80-4298-b94b-7c971efad4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aligned sentences source</th>\n",
       "      <th>aligned sentences target</th>\n",
       "      <th>sentences source</th>\n",
       "      <th>sentences target</th>\n",
       "      <th>aligned sentences source types</th>\n",
       "      <th>aligned sentences target types</th>\n",
       "      <th>sentences source types</th>\n",
       "      <th>sentences target types</th>\n",
       "      <th>predicted_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A histogram of the ^^^^^^^Va^^^ /slope for dw...</td>\n",
       "      <td>A histogram of the $_{\\rm max}$ /slope for dw...</td>\n",
       "      <td>A histogram of the Va /slope for dwarf irregu...</td>\n",
       "      <td>A histogram of the $_{\\rm max}$ /slope for dw...</td>\n",
       "      <td>W WWWWWWWWW WW WWW ^^^^^^^II^^^ WWWWWW WWW WW...</td>\n",
       "      <td>W WWWWWWWWW WW WWW IIIIIIIIIIII WWWWWW WWW WW...</td>\n",
       "      <td>W WWWWWWWWW WW WWW II WWWWWW WWW WWWWW WWWWWW...</td>\n",
       "      <td>W WWWWWWWWW WW WWW IIIIIIIIIIII WWWWWW WWW WW...</td>\n",
       "      <td>A histogram of the $V_{\\rm d}$ /slope for dwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Observations were carried out. using ^^a log ...</td>\n",
       "      <td>Observations were carried out@ using â a log ...</td>\n",
       "      <td>Observations were carried out. using a log of...</td>\n",
       "      <td>Observations were carried out using â a log o...</td>\n",
       "      <td>WWWWWWWWWWWW WWWW WWWWWWW WWWW WWWWW ^^W WWW ...</td>\n",
       "      <td>WWWWWWWWWWWW WWWW WWWWWWW WWW@ WWWWW W W WWW ...</td>\n",
       "      <td>WWWWWWWWWWWW WWWW WWWWWWW WWWW WWWWW W WWW WW...</td>\n",
       "      <td>WWWWWWWWWWWW WWWW WWWWWWW WWW WWWWW W W WWW W...</td>\n",
       "      <td>Observations were carried out using a log of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compared to a smooth polynomial. the flat fie...</td>\n",
       "      <td>Compared to a smooth polynomial, the flat fie...</td>\n",
       "      <td>Compared to a smooth polynomial. the flat fie...</td>\n",
       "      <td>Compared to a smooth polynomial, the flat fie...</td>\n",
       "      <td>WWWWWWWW WW W WWWWWW WWWWWWWWWWW WWW WWWW WWW...</td>\n",
       "      <td>WWWWWWWW WW W WWWWWW WWWWWWWWWWW WWW WWWW WWW...</td>\n",
       "      <td>WWWWWWWW WW W WWWWWW WWWWWWWWWWW WWW WWWW WWW...</td>\n",
       "      <td>WWWWWWWW WW W WWWWWW WWWWWWWWWWW WWW WWWW WWW...</td>\n",
       "      <td>Compared to a smooth polynomial, the flat fie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006) confirmed. lis scenario.</td>\n",
       "      <td>2006) confirmed this scenario.</td>\n",
       "      <td>2006) confirmed. lis scenario.</td>\n",
       "      <td>2006) confirmed this scenario.</td>\n",
       "      <td>WWWWW WWWWWWWWWW WWW WWWWWWWWW</td>\n",
       "      <td>WWWWW WWWWWWWWW WWWW WWWWWWWWW</td>\n",
       "      <td>WWWWW WWWWWWWWWW WWW WWWWWWWWW</td>\n",
       "      <td>WWWWW WWWWWWWWW WWWW WWWWWWWWW</td>\n",
       "      <td>2006) confirmed this scenario.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thus. slieht differences in ihe ^^^Â©C'a ^^^^v...</td>\n",
       "      <td>Thus, slight differences in the $\\Sigma Ca$ v...</td>\n",
       "      <td>Thus. slieht differences in ihe Â©C'a value of...</td>\n",
       "      <td>Thus, slight differences in the $\\Sigma Ca$ v...</td>\n",
       "      <td>WWWWW WWWWWW WWWWWWWWWWW WW WWW ^^^IIIII^^^^W...</td>\n",
       "      <td>WWWWW WWWWWW WWWWWWWWWWW WW WWW IIIIIIIIIII W...</td>\n",
       "      <td>WWWWW WWWWWW WWWWWWWWWWW WW WWW IIIIIWWWWW WW...</td>\n",
       "      <td>WWWWW WWWWWW WWWWWWWWWWW WW WWW IIIIIIIIIII W...</td>\n",
       "      <td>Thus, slight differences in the $\\phi$ Ca val...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            aligned sentences source  \\\n",
       "0   A histogram of the ^^^^^^^Va^^^ /slope for dw...   \n",
       "1   Observations were carried out. using ^^a log ...   \n",
       "2   Compared to a smooth polynomial. the flat fie...   \n",
       "3                     2006) confirmed. lis scenario.   \n",
       "4   Thus. slieht differences in ihe ^^^Â©C'a ^^^^v...   \n",
       "\n",
       "                            aligned sentences target  \\\n",
       "0   A histogram of the $_{\\rm max}$ /slope for dw...   \n",
       "1   Observations were carried out@ using â a log ...   \n",
       "2   Compared to a smooth polynomial, the flat fie...   \n",
       "3                     2006) confirmed this scenario.   \n",
       "4   Thus, slight differences in the $\\Sigma Ca$ v...   \n",
       "\n",
       "                                    sentences source  \\\n",
       "0   A histogram of the Va /slope for dwarf irregu...   \n",
       "1   Observations were carried out. using a log of...   \n",
       "2   Compared to a smooth polynomial. the flat fie...   \n",
       "3                     2006) confirmed. lis scenario.   \n",
       "4   Thus. slieht differences in ihe Â©C'a value of...   \n",
       "\n",
       "                                    sentences target  \\\n",
       "0   A histogram of the $_{\\rm max}$ /slope for dw...   \n",
       "1   Observations were carried out using â a log o...   \n",
       "2   Compared to a smooth polynomial, the flat fie...   \n",
       "3                     2006) confirmed this scenario.   \n",
       "4   Thus, slight differences in the $\\Sigma Ca$ v...   \n",
       "\n",
       "                      aligned sentences source types  \\\n",
       "0   W WWWWWWWWW WW WWW ^^^^^^^II^^^ WWWWWW WWW WW...   \n",
       "1   WWWWWWWWWWWW WWWW WWWWWWW WWWW WWWWW ^^W WWW ...   \n",
       "2   WWWWWWWW WW W WWWWWW WWWWWWWWWWW WWW WWWW WWW...   \n",
       "3                     WWWWW WWWWWWWWWW WWW WWWWWWWWW   \n",
       "4   WWWWW WWWWWW WWWWWWWWWWW WW WWW ^^^IIIII^^^^W...   \n",
       "\n",
       "                      aligned sentences target types  \\\n",
       "0   W WWWWWWWWW WW WWW IIIIIIIIIIII WWWWWW WWW WW...   \n",
       "1   WWWWWWWWWWWW WWWW WWWWWWW WWW@ WWWWW W W WWW ...   \n",
       "2   WWWWWWWW WW W WWWWWW WWWWWWWWWWW WWW WWWW WWW...   \n",
       "3                     WWWWW WWWWWWWWW WWWW WWWWWWWWW   \n",
       "4   WWWWW WWWWWW WWWWWWWWWWW WW WWW IIIIIIIIIII W...   \n",
       "\n",
       "                              sentences source types  \\\n",
       "0   W WWWWWWWWW WW WWW II WWWWWW WWW WWWWW WWWWWW...   \n",
       "1   WWWWWWWWWWWW WWWW WWWWWWW WWWW WWWWW W WWW WW...   \n",
       "2   WWWWWWWW WW W WWWWWW WWWWWWWWWWW WWW WWWW WWW...   \n",
       "3                     WWWWW WWWWWWWWWW WWW WWWWWWWWW   \n",
       "4   WWWWW WWWWWW WWWWWWWWWWW WW WWW IIIIIWWWWW WW...   \n",
       "\n",
       "                              sentences target types  \\\n",
       "0   W WWWWWWWWW WW WWW IIIIIIIIIIII WWWWWW WWW WW...   \n",
       "1   WWWWWWWWWWWW WWWW WWWWWWW WWW WWWWW W W WWW W...   \n",
       "2   WWWWWWWW WW W WWWWWW WWWWWWWWWWW WWW WWWW WWW...   \n",
       "3                     WWWWW WWWWWWWWW WWWW WWWWWWWWW   \n",
       "4   WWWWW WWWWWW WWWWWWWWWWW WW WWW IIIIIIIIIII W...   \n",
       "\n",
       "                                      predicted_text  \n",
       "0   A histogram of the $V_{\\rm d}$ /slope for dwa...  \n",
       "1   Observations were carried out using a log of ...  \n",
       "2   Compared to a smooth polynomial, the flat fie...  \n",
       "3                     2006) confirmed this scenario.  \n",
       "4   Thus, slight differences in the $\\phi$ Ca val...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df50 = pd.read_csv(output_dir_ + \"s50yelpfeast.csv\")\n",
    "df50.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "253a9c85-8759-47cc-9e41-f25661bb1ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_dist(df, text1, text2):\n",
    "    error = []\n",
    "    for i in range(df.shape[0]):\n",
    "#         print(distance(df[text1][i], df[text2][i]))\n",
    "        error.append(distance(df[text1][i], df[text2][i]))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31c5b2be-adbe-4f8f-bc81-dda6e079570f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.06"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cal_dist(df50, \"sentences source\", \"sentences target\"))/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ae26c32-1dde-4f15-bf96-769502147124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.58"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cal_dist(df50, \"predicted_text\", \"sentences target\"))/50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86675b67-f5b1-4d39-9dd1-a89a228636b0",
   "metadata": {},
   "source": [
    "run full dataset on each test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac352dad-5980-4c2b-b2c3-5438d5828138",
   "metadata": {},
   "source": [
    "1. train them both to the low point in validation error --> take around or two\n",
    "2. make sure it can run on the all dataset--> only one "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82f7be3-c042-4fa6-936e-a2ddf3b18917",
   "metadata": {},
   "source": [
    "# 'ufal/byt5-small-multilexnorm2021-es'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54b5d182-c6f2-4d80-b9e5-25fa114d5062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        A histogram of the Va /slope for dwarf irregu...\n",
       "1        Observations were carried out. using a log of...\n",
       "2        Compared to a smooth polynomial. the flat fie...\n",
       "3                          2006) confirmed. lis scenario.\n",
       "4        Thus. slieht differences in ihe Â©C'a value of...\n",
       "                              ...                        \n",
       "9995     TIe X-ray spectra obtaiied with previous low-...\n",
       "9996     This variation stems primarily from the initi...\n",
       "9997     Leroyetal.(2008) aud Dieielet used the 21 fux...\n",
       "9998     Making use of the approximation that p=X/H gi...\n",
       "9999           This is qualitatively consistent (see Fig.\n",
       "Name: sentences source, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = np.arange(0,len(test_df))\n",
    "text = test_df.iloc[inds][\"sentences source\"]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4940cfcb-bc2b-4b38-a35a-91debe448464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 : error or timeout in model\n"
     ]
    }
   ],
   "source": [
    "df2 = test_df.iloc[inds].copy()\n",
    "df2['predicted_text'] = None\n",
    "\n",
    "for i in range(text.shape[0]):\n",
    "    if i%100 == 0:\n",
    "        filename = output_dir_ + 's' + str(i) + ender + '.csv' \n",
    "        df2.to_csv(filename, index=False)\n",
    "    try: \n",
    "        with timeout(seconds=int(wait_timeout)):\n",
    "            inputs = tokenizer(text[i], padding=\"longest\", return_tensors=\"pt\")\n",
    "            output = model.generate(**inputs)\n",
    "            output_text = tokenizer.decode(output[0], \n",
    "                                            skip_special_tokens=skip_specials, \n",
    "                                            clean_up_tokenization_spaces=True)\n",
    "            output_text = str(output_text)\n",
    "    except:\n",
    "        #import sys; sys.exit()\n",
    "        print(i, ': error or timeout in model')\n",
    "        output_text = np.nan\n",
    "        err = True\n",
    "    df2['predicted_text'][i] = output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19130cb-2878-484b-baad-8dd0f929d8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:BIOE-488-v2]",
   "language": "python",
   "name": "conda-env-BIOE-488-v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
